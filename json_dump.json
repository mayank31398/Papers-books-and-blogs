[
    {
        "name": "1-bit Adam: communication efficient large-scale training with Adam\u2019s convergence speed",
        "url": "https://arxiv.org/abs/2102.02888",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Hanlin Tang, Shaoduo Gan, Ammar Ahmad Awan, Samyam Rajbhandari, Conglong Li, Xiangru Lian, Ji Liu, Ce Zhang, Yuxiong He",
        "keywords": ["Deep Learning", "Distributed Training"]
    },
    {
        "name": "5 best practices for efficient model training",
        "url": "https://www.mosaicml.com/blog/5-best-practices-for-efficient-model-training",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Matthew Leavitt, Abhinav Venigalla",
        "keywords": ["Deep Learning", "Faster Training", "Systems"]
    },
    {
        "name": "8-bit optimizers via block-wise quantization",
        "url": "https://arxiv.org/abs/2110.02861",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Tim Dettmers, Mike Lewis, Sam Shleifer, Luke Zettlemoyer",
        "keywords": ["Deep Learning", "Quantization"]
    },
    {
        "name": "A 'neural' network that learns to play Backgammon",
        "url": "https://papers.nips.cc/paper/30-a-neural-network-that-learns-to-play-backgammon",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Gerald Tesauro, Terrence J. Sejnowski",
        "keywords": ["Deep Learning"]
    },
    {
        "name": "A BetterTransformer for fast transformer inference",
        "url": "https://pytorch.org/blog/a-better-transformer-for-fast-transformer-encoder-inference/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Michael Gschwind, Eric Han, Scott Wolchok, Rui Zhu, Christian Puhrsch",
        "keywords": ["Deep Learning", "Systems", "Transformers"]
    },
    {
        "name": "A deep reinforced model for abstractive summarization",
        "url": "https://arxiv.org/abs/1705.04304",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Romain Paulus, Caiming Xiong, Richard Socher",
        "keywords": ["NLP", "Reinforcement Learning", "Summarization"]
    },
    {
        "name": "A dynamical approach to temporal pattern processing",
        "url": "https://papers.nips.cc/paper/76-a-dynamical-approach-to-temporal-pattern-processing",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "W. Scott Stornetta, Tad Hogg, Bernardo A. Huberman",
        "keywords": ["Deep Learning"]
    },
    {
        "name": "A fast quantum mechanical algorithm for database search",
        "url": "https://arxiv.org/abs/quant-ph/9605043",
        "topic": "Quantum Computing",
        "datatype": "Paper",
        "authors": "Lov K. Grover",
        "keywords": ["Quantum Algorithms", "Quantum Computing"]
    },
    {
        "name": "A few more examples may be worth billions of parameters",
        "url": "https://arxiv.org/abs/2110.04374",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Yuval Kirstain, Patrick Lewis, Sebastian Riedel, Omer Levy",
        "keywords": ["Few Shot", "NLP"]
    },
    {
        "name": "A general and adaptive robust loss function",
        "url": "https://arxiv.org/abs/1701.03077",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Jonathan T. Barron",
        "keywords": ["Deep Learning"]
    },
    {
        "name": "A gentle introduction to 8-bit matrix multiplication for transformers at scale using Hugging Face transformers, accelerate and bitsandbytes",
        "url": "https://huggingface.co/blog/hf-bitsandbytes-integration",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Younes Belkada, Tim Dettmers",
        "keywords": ["Deep Learning", "Quantization", "Transformers"]
    },
    {
        "name": "A note on the evaluation of generative models",
        "url": "https://arxiv.org/abs/1511.01844",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Lucas Theis, A\u00e4ron van den Oord, Matthias Bethge",
        "keywords": ["Deep Learning", "Generative Models"]
    },
    {
        "name": "A robust self-learning method for fully unsupervised cross-lingual mappings of word embeddings",
        "url": "https://arxiv.org/abs/1805.06297",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Mikel Artetxe, Gorka Labaka, Eneko Agirre",
        "keywords": ["Embeddings", "NLP"]
    },
    {
        "name": "A simple but tough-to-beat baseline for sentence embeddings",
        "url": "https://openreview.net/forum?id=SyK00v5xx",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Sanjeev Arora, Yingyu Liang, Tengyu Ma",
        "keywords": ["Embeddings", "NLP"]
    },
    {
        "name": "A simple language model for task-oriented dialogue",
        "url": "https://arxiv.org/abs/2005.00796",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Ehsan Hosseini-Asl, Bryan McCann, Chien-Sheng Wu, Semih Yavuz, Richard Socher",
        "keywords": ["Dialog", "NLP"]
    },
    {
        "name": "A simple neural attentive meta-learner",
        "url": "https://arxiv.org/abs/1707.03141",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Nikhil Mishra, Mostafa Rohaninejad, Xi Chen, Pieter Abbeel",
        "keywords": ["Deep Learning", "Few Shot", "Meta Learning"]
    },
    {
        "name": "A simple neural network module for relational reasoning",
        "url": "https://arxiv.org/abs/1706.01427",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Adam Santoro, David Raposo, David G.T. Barrett, Mateusz Malinowski, Razvan Pascanu, Peter Battaglia, Timothy Lillicrap",
        "keywords": ["Deep Learning", "Relational Reasoning"]
    },
    {
        "name": "A single quantum cannot be cloned",
        "url": "https://www.nature.com/articles/299802a0",
        "topic": "Quantum Computing",
        "datatype": "Paper",
        "authors": "W. K. Wootters, W. H. Zurek",
        "keywords": ["Quantum Computing"]
    },
    {
        "name": "A study of BFLOAT16 for deep learning training",
        "url": "https://arxiv.org/abs/1905.12322",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Dhiraj Kalamkar, Dheevatsa Mudigere, Naveen Mellempudi, Dipankar Das, Kunal Banerjee, Sasikanth Avancha, Dharma Teja Vooturi, Nataraj Jammalamadaka, Jianyu Huang, Hector Yuen, Jiyan Yang, Jongsoo Park, Alexander Heinecke, Evangelos Georganas, Sudarshan Srinivasan, Abhisek Kundu, Misha Smelyanskiy, Bharat Kaul, Pradeep Dubey",
        "keywords": ["Deep Learning", "Large Models"]
    },
    {
        "name": "A style-based generator architecture for generative adversarial networks",
        "url": "https://arxiv.org/abs/1812.04948",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Tero Karras, Samuli Laine, Timo Aila",
        "keywords": [
            "Adversarial Learning",
            "Deep Learning",
            "Generative Models"
        ]
    },
    {
        "name": "A stylometric inquiry into hyperpartisan and fake news",
        "url": "https://arxiv.org/abs/1702.05638",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Martin Potthast, Johannes Kiesel, Kevin Reinartz, Janek Bevendorff, Benno Stein",
        "keywords": ["Fake Content Detection", "NLP"]
    },
    {
        "name": "A3T: adversarially augmented adversarial training",
        "url": "https://arxiv.org/abs/1801.04055",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Akram Erraqabi, Aristide Baratin, Yoshua Bengio, Simon Lacoste-Julien",
        "keywords": [
            "Adversarial Learning",
            "Deep Learning",
            "Generative Models"
        ]
    },
    {
        "name": "Accelerated PyTorch 2 transformers",
        "url": "https://pytorch.org/blog/accelerated-pytorch-2/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Michael Gschwind, Driss Guessous, Christian Puhrsch",
        "keywords": ["Deep Learning", "Systems", "Transformers"]
    },
    {
        "name": "Accelerated computing with a reconfigurable dataflow architecture",
        "url": "https://sambanova.ai/wp-content/uploads/2021/04/SambaNova_Accelerated-Computing-with-a-Reconfigurable-Dataflow-Architecture_Whitepaper_English.pdf",
        "topic": "Computer Architecture",
        "datatype": "Whitepaper",
        "authors": null,
        "keywords": ["Dataflow Architecture", "Deep Learning"]
    },
    {
        "name": "Accelerating PyTorch with CUDA graphs",
        "url": "https://pytorch.org/blog/accelerating-pytorch-with-cuda-graphs/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Vinh Nguyen, Michael Carilli, Sukru Burc Eryilmaz, Vartika Singh, Michelle Lin, Natalia Gimelshein, Alban Desmaison, Edward Yang",
        "keywords": ["Deep Learning", "Large Models", "Systems"]
    },
    {
        "name": "Accelerating large language model training with variable sparse pre-training and dense fine-tuning",
        "url": "https://www.cerebras.net/blog/accelerating-llm-training-with-variable-sparse-pre-training-and-dense-fine-tuning/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Abhay Gupta, Mahmoud Salem, Vithursan Thangarasa, Kevin Leong, Sean Lie, Shreyas Saxena",
        "keywords": ["Large Models", "Sparse Matrices"]
    },
    {
        "name": "AdapterHub: a framework for adapting transformers",
        "url": "https://arxiv.org/abs/2007.07779",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Jonas Pfeiffer, Andreas R\u00fcckl\u00e9, Clifton Poth, Aishwarya Kamath, Ivan Vuli\u0107, Sebastian Ruder, Kyunghyun Cho, Iryna Gurevych",
        "keywords": ["Efficient Finetuning", "NLP", "Transformers"]
    },
    {
        "name": "Adversarial approximate inference for speech to electroglottograph conversion",
        "url": "https://arxiv.org/abs/1903.12248",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Prathosh A. P., Varun Srivastava, Mayank Mishra",
        "keywords": [
            "Adversarial Learning",
            "Approximate Inference",
            "Deep Learning",
            "Generative Models",
            "Speech"
        ]
    },
    {
        "name": "Adversarial autoencoders",
        "url": "https://arxiv.org/abs/1511.05644",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian Goodfellow, Brendan Frey",
        "keywords": [
            "Adversarial Learning",
            "Deep Learning",
            "Generative Models"
        ]
    },
    {
        "name": "Adversarial examples that fool both computer vision and time-limited humans",
        "url": "https://arxiv.org/abs/1802.08195",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Gamaleldin F. Elsayed, Shreya Shankar, Brian Cheung, Nicolas Papernot, Alex Kurakin, Ian Goodfellow, Jascha Sohl-Dickstein",
        "keywords": ["Adversarial Examples", "Deep Learning"]
    },
    {
        "name": "Adversarial feature learning",
        "url": "https://arxiv.org/abs/1605.09782",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Jeff Donahue, Philipp Kr\u00e4henb\u00fchl, Trevor Darrell",
        "keywords": [
            "Adversarial Learning",
            "Deep Learning",
            "Generative Models"
        ]
    },
    {
        "name": "Adversarial generation of natural language",
        "url": "https://arxiv.org/abs/1705.10929",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Sai Rajeswar, Sandeep Subramanian, Francis Dutil, Christopher Pal, Aaron Courville",
        "keywords": ["Adversarial Learning", "Generative Models", "NLP"]
    },
    {
        "name": "Adversarial information factorization",
        "url": "https://arxiv.org/abs/1711.05175",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Antonia Creswell, Yumnah Mohamied, Biswa Sengupta, Anil A Bharath",
        "keywords": [
            "Adversarial Learning",
            "Deep Learning",
            "Generative Models"
        ]
    },
    {
        "name": "Adversarially learned inference",
        "url": "https://arxiv.org/abs/1606.00704",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Vincent Dumoulin, Ishmael Belghazi, Ben Poole, Olivier Mastropietro, Alex Lamb, Martin Arjovsky, Aaron Courville",
        "keywords": [
            "Adversarial Learning",
            "Deep Learning",
            "Generative Models"
        ]
    },
    {
        "name": "AlexaTM 20B: few-shot learning using a large-scale multilingual seq2seq model",
        "url": "https://arxiv.org/abs/2208.01448",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Saleh Soltan, Shankar Ananthakrishnan, Jack FitzGerald, Rahul Gupta, Wael Hamza, Haidar Khan, Charith Peris, Stephen Rawls, Andy Rosenbaum, Anna Rumshisky, Chandana Satya Prakash, Mukund Sridhar, Fabian Triefenbach, Apurv Verma, Gokhan Tur, Prem Natarajan",
        "keywords": ["Large Models", "NLP", "Transformers"]
    },
    {
        "name": "Amazon SageMaker model parallelism: a general and flexible framework for large model training",
        "url": "https://arxiv.org/abs/2111.05972",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Can Karakus, Rahul Huilgol, Fei Wu, Anirudh Subramanian, Cade Daniel, Derya Cavdar, Teng Xu, Haohan Chen, Arash Rahnama, Luis Quintela",
        "keywords": [
            "Deep Learning",
            "Distributed Training",
            "Large Models",
            "Systems"
        ]
    },
    {
        "name": "An image is worth 16x16 words: transformers for image recognition at scale",
        "url": "https://arxiv.org/abs/2010.11929",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby",
        "keywords": ["Computer Vision"]
    },
    {
        "name": "An overview of gradient descent optimization algorithms",
        "url": "https://arxiv.org/abs/1609.04747",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Sebastian Ruder",
        "keywords": ["Deep Learning", "Optimization"]
    },
    {
        "name": "Analysing mathematical reasoning abilities of neural models",
        "url": "https://arxiv.org/abs/1904.01557",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "David Saxton, Edward Grefenstette, Felix Hill, Pushmeet Kohli",
        "keywords": ["Deep Learning"]
    },
    {
        "name": "Approximation by superpositions of sigmoidal function",
        "url": "https://link.springer.com/article/10.1007/BF02551274",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "George Cybenko",
        "keywords": ["Deep Learning"]
    },
    {
        "name": "Artificial Intelligence: a modern approach",
        "url": null,
        "topic": "AI, DL, NLP and RL",
        "datatype": "Book",
        "authors": "Stuart Russell, Peter Norvig",
        "keywords": null
    },
    {
        "name": "Aspect based sentiment analysis with gated convolutional networks",
        "url": "https://arxiv.org/abs/1805.07043",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Wei Xue, Tao Li",
        "keywords": ["NLP", "Text Classification"]
    },
    {
        "name": "Attention is all you need",
        "url": "https://arxiv.org/abs/1706.03762",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, \u0141ukasz Kaiser, Illia Polosukhin",
        "keywords": ["Attention Mechanism", "Deep Learning", "Transformers"]
    },
    {
        "name": "Attention is off by one",
        "url": "https://www.evanmiller.org/attention-is-off-by-one.html",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Evan Miller",
        "keywords": ["Attention Mechanism", "NLP"]
    },
    {
        "name": "Auto-encoding variational Bayes",
        "url": "https://arxiv.org/abs/1312.6114",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Diederik P. Kingma, Max Welling",
        "keywords": [
            "Deep Learning",
            "Generative Models",
            "Variational Inference"
        ]
    },
    {
        "name": "BART: denoising sequence-to-sequence pre-training for natural language generation, translation and comprehension",
        "url": "https://arxiv.org/abs/1910.13461",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, Luke Zettlemoyer",
        "keywords": ["NLP", "Transformers"]
    },
    {
        "name": "BERT: pre-training of deep bidirectional transformers for language understanding",
        "url": "https://arxiv.org/abs/1810.04805",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova",
        "keywords": ["NLP", "Transformers"]
    },
    {
        "name": "BLOOM: A 176B-parameter open-access multilingual language model",
        "url": "https://arxiv.org/abs/2211.05100",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Aaron Gokaslan, Abheesht Sharma, Abhinav Ramesh Kashyap, Adam Roberts, Adi Simhi, Ahmed Baruwa, Aitor Soroa, Albert Villanova del Moral, Albert Webson, Alexander M. Rush, Alexandra Sasha Luccioni, Alfredo Palasciano, Alham Fikri Aji, Alice Rueda, Alison Callahan, Amanda Pestana, Amanpreet Singh, Amir Feizpour, Amit Alfassy, Ammar Khan, Amy Faranak, Ana Santos, Anastasia Cheveleva, Andrea Santilli, Angela Fan, Angelina McMillan-Major, Anima Shukla, Anna Rogers, Anne-Laure Ligozat, Anthony Hevia, Antigona Unldreaj, Antoine Chaffin, Antonio Miranda-Escalada, Arash Aghagol, Arezoo Abdollahi, Ariel Kreisberg Nitzav, Arjun Subramonian, Arnaud Stiegler, Arun Raja, Aur\u00e9lie N\u00e9v\u00e9ol, Aycha Tammour, Ayush Singh, Azadeh HajiHosseini, Bahareh Behroozi, Benjamin Ajibade, Benjamin Beilharz, Benjamin Heinzerling, Beno\u00eet Sagot, Bharat Saxena, Bo Wang, Caio Brito, Canwen Xu, Carlos Mu\u00f1oz Ferrandis, Charles Lovering, Chenghao Mou, Chenglei Si, Chenxi Zhou, Chirag Jain, Chris Emezue, Christopher Akiki, Christopher Klamm, Chuxin Xu, Cl\u00e9mentine Fourrier, Colin Leong, Colin Raffel, Conglong Li, Dan Garrette, Daniel Hesslow, Daniel Le\u00f3n Peri\u00f1\u00e1n, Daniel Molano, Daniel van Strien, Danish Contractor, David Ifeoluwa Adelani, David Lansky, Davis David, Davut Emre Ta\u015far, Debajyoti Datta, Deepak Narayanan, Deepak Tunuguntla, Dian Yu, Douwe Kiela, Dragomir Radev, Duong A. Nguyen, Eduardo Gonz\u00e1lez Ponferrada, Edward Tan, Efrat Levkovizh, Ehud Reiter, Ekaterina Taktasheva, Ekaterina Voloshina, Eli Bogdanov, Eliza Szczechla, Elizabeth Salesky, Ellie Pavlick, Emi Baylor, Enrique Manjavacas, Ethan Kim, Eyal Bar Natan, Ezinwanne Ozoani, Fabio Barth, Fatima Mirza, Florian Fuhrimann, Francesco De Toni, Frankline Ononiwu, Fran\u00e7ois Yvon, Gabriel Altay, Genta Indra Winata, Germ\u00e1n Kruszewski, Giada Pistilli, Giyaseddin Bayrak, Gully Burns, Gunjan Chhablani, G\u00e9rard Dupont, Habib Rezanejad, Hadar Tojarieh, Hady Elsahar, Hailey Schoelkopf, Hamza Benyamina, Han Wang, Harshit Pandey, Hatim Bourfoune, Helena U. Vrabec, Hendrik Strobelt, Hessie Jones, Hieu Tran, Hugo Lauren\u00e7on, Huu Nguyen, Hyung Won Chung, Ian Yu, Idris Abdulmumin, Imane Bello, Indrani Bhattacharya, Irene Solaiman, Irina Sedenko, Isaac Johnson, Isar Nejadgholi, Ishani Dash, Itziar Gonzalez-Dios, Iz Beltagy, Jaesung Tae, Jan-Christoph Kalo, Jared Casper, Jason Alan Fries, Jason Phang, Javier de la Rosa, Jeff Rasley, Jekaterina Novikova, Jenny Chim, Jesse Dodge, Jesse Passmore, Jessica Zosa Forde, Jian Zhu, Jihyun Kang, John Giorgi, Jonas Golde, Jonathan Chang, Jonathan Tow, Jordan Clive, Jos Rozen, Jose David Posada, Joseph Tobing, Josh Seltzer, Joydeep Bhattacharjee, Julien Launay, Julio Bonis Sanz, Jungo Kasai, J\u00f6rg Frohberg, Karthik Rangasai Sivaraman, Ken Kawamura, Khalid Almubarak, Kimbo Chen, Kyle Lo, Leandro Von Werra, Leo Gao, Leon Weber, Liam Hazan, Lintang Sutawika, Livia Dutra, Lokesh Bulchandani, Long Phan, Loubna Ben allal, Lu Liu, Lucile Saulnier, Ludovic Tanguy, Luisa Shinzato, M Saiful Bari, Madeleine Hahn de Bykhovetz, Maged S. Al-shaibani, Maiko Takeuchi, Mairon Samagaio, Manan Dey, Manuel Romero Mu\u00f1oz, Maraim Elbadri, Maraim Masoud, Marc P\u00e0mies, Margaret Mitchell, Margot Mieskes, Maria A Castillo, Marianna Nezhurina, Marine Carpuat, Mario S\u00e4nger, Mario \u0160a\u0161ko, Marissa Gerchick, Martha Akinlolu, Mar\u00eda Grandury, Mathilde Bras, Matteo Manica, Matthias Gall\u00e9, Matthias Samwald, Max Huang, Max Ryabinin, Maximin Coavoux, Mayank Mishra, Mayank Singh, Michael Cullan, Michael McKenna, Michael Weinberg, Michiel De Wolf, Mike Qiu, Mike Tian-Jian Jiang, Mina Mihaljcic, Minh Chien Vu, Minjia Zhang, Minna Liu, Miruna Clinciu, Mohammad A. Jauhar, Mohammad Shoeybi, Moritz Freidank, Muhammed Ghauri, Mustafa Ghaleb, Mykola Burynok, Myriam Peyrounette, Myungsun Kang, Nafis Abrar, Najoung Kim, Natasha Seelam, Nathan Dahlberg, Nazneen Rajani, Newton Cheng, Nicholas Michio Broad, Nicolas Patry, Nihal Nayak, Niklas Muennighoff, Nikolaus Muellner, Nishant Subramani, Nora Kassner, Nouamane Tazi, Nour Elkott, Nour Fahmy, Nurulaqilla Khamis, Ofir Press, Olanrewaju Samuel, Olatunji Ruwase, Oleg Serikov, Olivier Nguyen, Omar Espejel, Omar Sanseviero, Omer Antverg, Ona de Gibert, Oskar van der Wal, Pascale Fung, Patrick Haller, Patrick von Platen, Paulo Villegas, Pawan Sasanka Ammanamanchi, Pedro Ortiz Suarez, Peter Henderson, Pierre Colombo, Pierre Cornette, Pierre Fran\u00e7ois Lavall\u00e9e, Priscilla Amuok, Quentin Lhoest, Rachel Bawden, Ramya Chandrasekhar, Ran An, Rasmus Kromann, Renata Eisenberg, Rheza Harliman, Rishi Bommasani, Robert Martin, Roberto Luis L\u00f3pez, Rodrigo Canalli, Roman Castagn\u00e9, Rosaline Su, Rui Ribeiro, Rui Zhang, Ruisi Su, Ruochen Zhang, Ryan Hao, Ryan Teehan, R\u00e9mi Lacroix, Sabrina J. Mielke, Salomey Osei, Samira Alizadeh, Sampo Pyysalo, Samson Tan, Samuel Albanie, Samuel Cahyawijaya, Samuele Garda, Samyam Rajbhandari, Sanchit Gandhi, Sarmad Shubber, Sebastian Gehrmann, Sebastian Nagel, Shachar Mirkin, Shaden Smith, Shaked Brody, Shamik Bose, Shamsuddeen Hassan Muhammad, Shani Pais, Shanya Sharma, Shayne Longpre, Sheng Shen, Shlok S Deshmukh, Shubhanshu Mishra, Sid Kiblawi, Silas Wang, Simon Ott, Sinee Sang-aroonsiri, Somaieh Nikpoor, Sourav Roy, Srishti Kumar, Srulik Ben-David, Stanislav Silberberg, Stas Bekman, Stefan Schweter, Stella Biderman, Stephen H. Bach, St\u00e9phane Requena, Suhas Pai, Suraj Patil, Sushil Bharati, Suzana Ili\u0107, Sydney Zink, Sylvain Viguier, Taewoon Kim, Tali Bers, Tanmay Laud, Tatiana Shavrina, Teven Le Scao, Thanh Le, Thibault Fevry, Thomas Scialom, Thomas Wang, Thomas Wolf, Th\u00e9o Gigant, Tiago Timponi Torrent, Tian Yun, Tim Dettmers, Timo Schick, Tobi Oyebade, Tomasz Limisiewicz, Tomoya Kainuma, Trieu Le, Trishala Neeraj, Tristan Thrush, Urmish Thakker, Valentin Danchev, Vassilina Nikoulina, Verena Rieser, Veronika Laippala, Victor Sanh, Vikas Raunak, Violette Lepercq, Vitaly Protasov, Vladislav Mikhailov, Vrinda Prabhu, Wilson Y. Lee, Wojciech Kusa, Xiangru Tang, Yacine Jernite, Yada Pruksachatkun, Yallow Uri, Yanis Labrak, Yash Shailesh Bajaj, Yash Venkatraman, Yifan Xu, Yingxin Xu, Yonatan Belinkov, Younes Belkada, Yoyo Yang, Yu Xu, Zach Nguyen, Zachary Bamberger, Zaid Alyafeai, Zden\u011bk Kasner, Zeerak Talat, Zhe Tan, Zheng-Xin Yong, Zhiqing Sun, Zhongli Xie, Zifan Ye",
        "keywords": [
            "Distributed Training",
            "Large Models",
            "NLP",
            "Transformers"
        ]
    },
    {
        "name": "BTLM-3B-8K: 7B performance in a 3 billion parameter model",
        "url": "https://www.cerebras.net/machine-learning/btlm-3b-8k-7b-performance-in-a-3-billion-parameter-model/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Nolan Dey, Daria Soboleva, Faisal Al-Khateeb, Ribhu Pathria, Hemant Khachane, Shaheer Muhammad, Zhiming (Charles) Chen, Bowen Yang, Siyun Li, Abhay Gupta, Shreyas Saxena, Robert Myers, Jacob Robert Steeves, Marvin Tom, Joel Hestness",
        "keywords": ["Large Models", "NLP", "Transformers"]
    },
    {
        "name": "Backpropagation through the void: optimizing control variates for black-box gradient estimation",
        "url": "https://arxiv.org/abs/1711.00123",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Will Grathwohl, Dami Choi, Yuhuai Wu, Geoffrey Roeder, David Duvenaud",
        "keywords": [
            "Backpropagation",
            "Deep Learning",
            "Discrete Optimization",
            "Gradient Estimation",
            "Optimization",
            "Reinforcement Learning",
            "Variational Inference"
        ]
    },
    {
        "name": "Batch normalization: accelerating deep network training by reducing internal covariate shift",
        "url": "https://arxiv.org/abs/1502.03167",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Sergey Ioffe, Christian Szegedy",
        "keywords": ["Deep Learning", "Normalization", "Optimization"]
    },
    {
        "name": "Behavioral cloning from observation",
        "url": "https://arxiv.org/abs/1805.01954",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Faraz Torabi, Garrett Warnell, Peter Stone",
        "keywords": [
            "Behavior and Control",
            "Deep Learning",
            "Genetic Algorithms",
            "Robotics"
        ]
    },
    {
        "name": "Beyond domain APIs: Task-oriented conversational modeling with unstructured knowledge access",
        "url": "https://arxiv.org/abs/2006.03533",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Seokhwan Kim, Mihail Eric, Karthik Gopalakrishnan, Behnam Hedayatnia, Yang Liu, Dilek Hakkani-Tur",
        "keywords": ["Dialog", "NLP"]
    },
    {
        "name": "Bootstrapping entity alignment with knowledge graph embedding",
        "url": "https://www.ijcai.org/proceedings/2018/611",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Zequn Sun, Wei Hu, Qingheng Zhang, Yuzhong Qu",
        "keywords": ["Embeddings", "Knowledge Graphs", "NLP"]
    },
    {
        "name": "Bridging the gap between prior and posterior knowledge selection for knowledge-grounded dialogue generation",
        "url": "https://www.aclweb.org/anthology/2020.emnlp-main.275/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Xiuyi Chen, Fandong Meng, Peng Li, Feilong Chen, Shuang Xu, Bo Xu, Jie Zhou",
        "keywords": ["Dialog", "NLP", "Variational Inference"]
    },
    {
        "name": "Bringing open large language models to consumer devices",
        "url": "https://mlc.ai/blog/2023/05/22/bringing-open-large-language-models-to-consumer-devices",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "MLC Community",
        "keywords": [
            "Deep Learning",
            "Deployment",
            "Machine Learning Compilation"
        ]
    },
    {
        "name": "Calculus of variations",
        "url": null,
        "topic": "Calculus",
        "datatype": "Book",
        "authors": "I. M. Gelfand, S. V. Fomin",
        "keywords": null
    },
    {
        "name": "Can quantum-mechanical description of physical reality be considered complete",
        "url": "https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777",
        "topic": "Quantum Computing",
        "datatype": "Paper",
        "authors": "Albert Einstein, Boris Podolsky, Nathan Rosen",
        "keywords": ["Quantum Computing"]
    },
    {
        "name": "ChatGPT: optimizing language models for dialogue",
        "url": "https://openai.com/blog/chatgpt/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": null,
        "keywords": ["Dialog", "NLP"]
    },
    {
        "name": "ColBERT: efficient and effective passage search via contextualized late interaction over BERT",
        "url": "https://arxiv.org/abs/2004.12832",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Omar Khattab, Matei Zaharia",
        "keywords": ["Information Retrieval", "NLP"]
    },
    {
        "name": "Colossal-AI: a unified deep learning system for large-scale parallel training",
        "url": "https://arxiv.org/abs/2110.14883",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Zhengda Bian, Hongxin Liu, Boxiang Wang, Haichen Huang, Yongbin Li, Chuanrui Wang, Fan Cui, Yang You",
        "keywords": [
            "Deep Learning",
            "Distributed Training",
            "Large Models",
            "Systems"
        ]
    },
    {
        "name": "Compiling machine learning programs via high-level tracing",
        "url": "https://research.google/pubs/pub47008/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Roy Frostig, Matthew Johnson, Chris Leary",
        "keywords": ["Deep Learning", "Systems"]
    },
    {
        "name": "Complex transformer: a framework for modeling complex-valued sequence",
        "url": "https://arxiv.org/abs/1910.10202",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Muqiao Yang, Martin Q. Ma, Dongyu Li, Yao-Hung Hubert Tsai, Ruslan Salakhutdinov",
        "keywords": ["Complex Numbers", "Deep Learning", "Transformers"]
    },
    {
        "name": "Computer architecture: a quantitative approach",
        "url": null,
        "topic": "Computer Architecture",
        "datatype": "Book",
        "authors": "John L. Hennessy, David A. Patterson",
        "keywords": null
    },
    {
        "name": "Computer organization and design ARM edition: the hardware software interface",
        "url": null,
        "topic": "Computer Architecture",
        "datatype": "Book",
        "authors": "David A. Patterson, John L. Hennessy",
        "keywords": null
    },
    {
        "name": "Conceptual captions: a cleaned, hypernymed, image alt-text dataset for automatic image captioning",
        "url": "https://aclanthology.org/P18-1238/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Piyush Sharma, Nan Ding, Sebastian Goodman, Radu Soricut",
        "keywords": ["Computer Vision", "Dataset", "NLP"]
    },
    {
        "name": "Conditional image synthesis with auxilliary classifier GANs",
        "url": "https://arxiv.org/abs/1610.09585",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Augustus Odena, Christopher Olah, Jonathon Shlens",
        "keywords": [
            "Adversarial Learning",
            "Deep Learning",
            "Generative Models"
        ]
    },
    {
        "name": "Conformal nucleus sampling",
        "url": "https://arxiv.org/abs/2305.02633",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Shauli Ravfogel, Yoav Goldberg, Jacob Goldberger",
        "keywords": ["NLP", "Transformers"]
    },
    {
        "name": "Connecting large language models with evolutionary algorithms yields powerful prompt optimizers",
        "url": "https://arxiv.org/abs/2309.08532",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Qingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao Song, Xu Tan, Guoqing Liu, Jiang Bian, Yujiu Yang",
        "keywords": ["Genetic Algorithms", "NLP", "Prompting"]
    },
    {
        "name": "Connectivity versus entropy",
        "url": "https://papers.nips.cc/paper/63-connectivity-versus-entropy",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Yaser S. Abu-Mostafa",
        "keywords": ["Deep Learning"]
    },
    {
        "name": "Constituency parsing with a self-attentive encoder",
        "url": "https://arxiv.org/abs/1805.01052",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Nikita Kitaev, Dan Klein",
        "keywords": ["Constituency Parsing", "NLP"]
    },
    {
        "name": "Constraint based knowledge base distillation in end-to-end task oriented dialogs",
        "url": "https://arxiv.org/abs/2109.07396",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Dinesh Raghu, Atishya Jain, Mausam, Sachindra Joshi",
        "keywords": ["Dialog", "NLP"]
    },
    {
        "name": "Context generation improves open domain question answering",
        "url": "https://arxiv.org/abs/2210.06349",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Dan Su, Mostofa Patwary, Shrimai Prabhumoye, Peng Xu, Ryan Prenger, Mohammad Shoeybi, Pascale Fung, Anima Anandkumar, Bryan Catanzaro",
        "keywords": ["Few Shot", "NLP", "Question Answering"]
    },
    {
        "name": "Convert transformers to ONNX with hugging face optimum",
        "url": "https://huggingface.co/blog/convert-transformers-to-onnx",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Philipp Schmid",
        "keywords": ["Deep Learning", "Model Saving", "Systems"]
    },
    {
        "name": "Convex Optimization",
        "url": null,
        "topic": "Optimization Theory",
        "datatype": "Book",
        "authors": "Stephen Boyd, Lieven Vandenberghe",
        "keywords": null
    },
    {
        "name": "Convolutional networks for graphs for learning molecular fingerprints",
        "url": "https://arxiv.org/abs/1509.09292",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "David K. Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell, Timothy Hirzel, Alan Aspuru-Guzik, Ryan P. Adams",
        "keywords": ["Deep Learning", "Molecular Chemistry"]
    },
    {
        "name": "Convolutional neural network language models",
        "url": "https://aclanthology.org/D16-1123/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Ngoc-Quan Pham, Germ\u00e1n Kruszewski, Gemma Boleda",
        "keywords": ["NLP"]
    },
    {
        "name": "Countering adversarial images using input transformations",
        "url": "https://arxiv.org/abs/1711.00117",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Chuan Guo, Mayank Rana, Moustapha Cisse, Laurens van der Maaten",
        "keywords": ["Adversarial Examples", "Deep Learning", "Robustness"]
    },
    {
        "name": "Cramming: training a language model on a single GPU in one day",
        "url": "https://arxiv.org/abs/2212.14034",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Jonas Geiping, Tom Goldstein",
        "keywords": ["Green AI", "NLP"]
    },
    {
        "name": "Crosslingual generalization through multitask finetuning",
        "url": "https://arxiv.org/abs/2211.01786",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman, Teven Le Scao, M Saiful Bari, Sheng Shen, Zheng-Xin Yong, Hailey Schoelkopf, Xiangru Tang, Dragomir Radev, Alham Fikri Aji, Khalid Almubarak, Samuel Albanie, Zaid Alyafeai, Albert Webson, Edward Raff, Colin Raffel",
        "keywords": [
            "Distributed Training",
            "Instruction Finetuning",
            "Large Models",
            "NLP",
            "Transformers"
        ]
    },
    {
        "name": "Curriculum learning",
        "url": "https://dl.acm.org/citation.cfm?id=1553380",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Yoshua Bengio, J\u00e9r\u00f4me Louradour, Ronan Collobert, Jason Weston",
        "keywords": ["Curriculum Learning", "Deep Learning"]
    },
    {
        "name": "Cutting down on prompts and parameters: simple few-shot learning with language models",
        "url": "https://arxiv.org/abs/2106.13353",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Robert L. Logan IV, Ivana Bala\u017eevi\u0107, Eric Wallace, Fabio Petroni, Sameer Singh, Sebastian Riedel",
        "keywords": ["Efficient Finetuning", "Few Shot", "NLP"]
    },
    {
        "name": "Data structures and algorithms in Java",
        "url": null,
        "topic": "Data Structures and Algorithms",
        "datatype": "Book",
        "authors": "Michael T. Goodrich, Roberto Tamassia, Michael H. Goldwasser",
        "keywords": null
    },
    {
        "name": "Deep Boltzmann machines",
        "url": "https://proceedings.mlr.press/v5/salakhutdinov09a.html",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Ruslan Salakhutdinov, Geoffrey Hinton",
        "keywords": [
            "Boltzmann Machines",
            "Deep Learning",
            "Energy-based Models"
        ]
    },
    {
        "name": "Deep complex networks",
        "url": "https://arxiv.org/abs/1705.09792",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Chiheb Trabelsi, Olexa Bilaniuk, Ying Zhang, Dmitriy Serdyuk, Sandeep Subramanian, Jo\u00e3o Felipe Santos, Soroush Mehri, Negar Rostamzadeh, Yoshua Bengio, Christopher J Pal",
        "keywords": ["Complex Numbers", "Deep Learning"]
    },
    {
        "name": "Deep learning",
        "url": null,
        "topic": "AI, DL, NLP and RL",
        "datatype": "Book",
        "authors": "Ian Goodfellow, Yoshua Bengio, Aaron Courville",
        "keywords": null
    },
    {
        "name": "Deep learning and the information bottleneck principle",
        "url": "https://arxiv.org/abs/1503.02406",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Naftali Tishby, Noga Zaslavsky",
        "keywords": ["Deep Learning", "Information Theory"]
    },
    {
        "name": "Deep learning techniques for super-resolution in video games",
        "url": "https://arxiv.org/abs/2012.09810",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Alexander Watson",
        "keywords": [
            "Computer Graphics",
            "Computer Vision",
            "Deep Learning",
            "Image Super Resolution"
        ]
    },
    {
        "name": "Deep residual learning for image recognition",
        "url": "https://arxiv.org/abs/1512.03385",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun",
        "keywords": ["Computer Vision", "Image Classification"]
    },
    {
        "name": "Deep text classification can be fooled",
        "url": "https://arxiv.org/abs/1704.08006",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Bin Liang, Hongcheng Li, Miaoqiang Su, Pan Bian, Xirong Li, Wenchang Shi",
        "keywords": ["Adversarial Examples", "NLP"]
    },
    {
        "name": "DeepSpeed Inference: enabling efficient inference of transformer models at unprecedented scale",
        "url": "https://arxiv.org/abs/2207.00032",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Reza Yazdani Aminabadi, Samyam Rajbhandari, Minjia Zhang, Ammar Ahmad Awan, Cheng Li, Du Li, Elton Zheng, Jeff Rasley, Shaden Smith, Olatunji Ruwase, Yuxiong He",
        "keywords": ["Deep Learning", "Large Models", "Systems"]
    },
    {
        "name": "DeepSpeed compression: a composable library for extreme compression and zero-cost quantization",
        "url": "https://www.microsoft.com/en-us/research/blog/deepspeed-compression-a-composable-library-for-extreme-compression-and-zero-cost-quantization/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "DeepSpeed Team, Andrey Proskurin",
        "keywords": ["Compression", "Deep Learning", "Quantization"]
    },
    {
        "name": "DeepSpeed powers 8x larger MoE model training with high performance",
        "url": "https://www.microsoft.com/en-us/research/blog/deepspeed-powers-8x-larger-moe-model-training-with-high-performance/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "DeepSpeed Team, Z-code Team",
        "keywords": [
            "Deep Learning",
            "Large Models",
            "Mixture of Experts",
            "Transformers"
        ]
    },
    {
        "name": "DeepSpeed: accelerating large-scale model inference and training via system optimizations and compression",
        "url": "https://www.microsoft.com/en-us/research/blog/deepspeed-accelerating-large-scale-model-inference-and-training-via-system-optimizations-and-compression/#:~:text=DeepSpeed%20Inference%20also%20supports%20fast,multiple%20GPUs%20for%20parallel%20execution.",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "DeepSpeed Team, Rangan Majumder, Andrey Proskurin",
        "keywords": ["Deep Learning", "Large Models", "Systems"]
    },
    {
        "name": "DeepSpeed: advancing MoE inference and training to power next-generation AI scale",
        "url": "https://www.microsoft.com/en-us/research/blog/deepspeed-advancing-moe-inference-and-training-to-power-next-generation-ai-scale/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "DeepSpeed Team, Andrey Proskurin",
        "keywords": [
            "Deep Learning",
            "Large Models",
            "Mixture of Experts",
            "Transformers"
        ]
    },
    {
        "name": "Denoising distantly supervised open-domain question answering",
        "url": "https://aclanthology.org/P18-1161/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Yankai Lin, Haozhe Ji, Zhiyuan Liu, Maosong Sun",
        "keywords": ["NLP", "Question Answering"]
    },
    {
        "name": "Diffusion convolutional recurrent neural network: data-driven traffic forecasting",
        "url": "https://arxiv.org/abs/1707.01926",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Yaguang Li, Rose Yu, Cyrus Shahabi, Yan Liu",
        "keywords": [
            "Deep Learning",
            "Graph Neural Networks",
            "Spatio-Temporal",
            "Time Series"
        ]
    },
    {
        "name": "Digital design: with an introduction to the Verilog HDL",
        "url": null,
        "topic": "Digital Electronics",
        "datatype": "Book",
        "authors": "M. Morris Mano, Michael D. Ciletti",
        "keywords": null
    },
    {
        "name": "Discrete variational autoencoders",
        "url": "https://arxiv.org/abs/1609.02200",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Jason Tyler Rolfe",
        "keywords": [
            "Deep Learning",
            "Generative Models",
            "Variational Inference"
        ]
    },
    {
        "name": "Discrete-time signal processing",
        "url": null,
        "topic": "Signal Processing",
        "datatype": "Book",
        "authors": "Alan V. Oppenheim, Ronald W. Schafer",
        "keywords": null
    },
    {
        "name": "Disentangling by factorising",
        "url": "https://arxiv.org/abs/1802.05983",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Hyunjik Kim, Andriy Mnih",
        "keywords": [
            "Deep Learning",
            "Disentanglement",
            "Generative Models",
            "Variational Inference"
        ]
    },
    {
        "name": "Disentangling language and knowledge in task-oriented dialogs",
        "url": "https://arxiv.org/abs/1805.01216",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Dinesh Raghu, Nikhil Gupta, Mausam",
        "keywords": ["Dialog", "Disentanglement", "NLP"]
    },
    {
        "name": "Distributed optimization and statistical learning via the alternating direction method of multipliers",
        "url": "https://ieeexplore.ieee.org/document/8186925",
        "topic": "Optimization Theory",
        "datatype": "Book",
        "authors": "Stephen Boyd, Neal Parikh, Eric Chu, Borja Peleato, Jonathan Eckstein",
        "keywords": null
    },
    {
        "name": "Distributionally robust language modeling",
        "url": "https://arxiv.org/abs/1909.02060",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Yonatan Oren, Shiori Sagawa, Tatsunori B. Hashimoto, Percy Liang",
        "keywords": ["NLP", "Out-of-Distribution", "Robustness"]
    },
    {
        "name": "Efficient estimation of word representations in vector space",
        "url": "https://arxiv.org/abs/1301.3781",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean",
        "keywords": ["Embeddings", "NLP"]
    },
    {
        "name": "Efficient large scale language modeling with mixtures of experts",
        "url": "https://arxiv.org/abs/2112.10684",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Mikel Artetxe, Shruti Bhosale, Naman Goyal, Todor Mihaylov, Myle Ott, Sam Shleifer, Xi Victoria Lin, Jingfei Du, Srinivasan Iyer, Ramakanth Pasunuru, Giri Anantharaman, Xian Li, Shuohui Chen, Halil Akin, Mandeep Baines, Louis Martin, Xing Zhou, Punit Singh Koura, Brian O'Horo, Jeff Wang, Luke Zettlemoyer, Mona Diab, Zornitsa Kozareva, Ves Stoyanov",
        "keywords": ["Deep Learning", "Large Models", "NLP", "Transformers"]
    },
    {
        "name": "Efficient large-scale language model training on GPU clusters using Megatron-LM",
        "url": "https://arxiv.org/abs/2104.04473",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Deepak Narayanan, Mohammad Shoeybi, Jared Casper, Patrick LeGresley, Mostofa Patwary, Vijay Anand Korthikanti, Dmitri Vainbrand, Prethvi Kashinkunti, Julie Bernauer, Bryan Catanzaro, Amar Phanishayee, Matei Zaharia",
        "keywords": [
            "Deep Learning",
            "Distributed Training",
            "Large Models",
            "Transformers"
        ]
    },
    {
        "name": "Elements of information theory",
        "url": null,
        "topic": "Information Theory",
        "datatype": "Book",
        "authors": "Thomas M. Cover, Joy A. Thomas",
        "keywords": null
    },
    {
        "name": "Enchancing the reliability of out-of-distribution image detection in neural networks",
        "url": "https://arxiv.org/abs/1706.02690",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Shiyu Liang, Yixuan Li, R. Srikant",
        "keywords": ["Deep Learning", "Out-of-Distribution"]
    },
    {
        "name": "End-to-end task-oriented dialog modeling with semi-structured knowledge management",
        "url": "https://arxiv.org/abs/2106.11796",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Silin Gao, Ryuichi Takanobu, Antoine Bosselut, Minlie Huang",
        "keywords": ["Dialog", "NLP"]
    },
    {
        "name": "Ensemble adversarial training: attacks and defenses",
        "url": "https://arxiv.org/abs/1705.07204",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Florian Tram\u00e8r, Alexey Kurakin, Nicolas Papernot, Ian Goodfellow, Dan Boneh, Patrick McDaniel",
        "keywords": ["Adversarial Examples", "Deep Learning", "Robustness"]
    },
    {
        "name": "Equilibrium propagation: bridging the gap between energy-based models and backpropagation",
        "url": "https://arxiv.org/abs/1602.05179",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Benjamin Scellier, Yoshua Bengio",
        "keywords": ["Backpropagation", "Deep Learning", "Enery based Models"]
    },
    {
        "name": "Error detecting and error correcting codes",
        "url": "https://ieeexplore.ieee.org/document/6772729",
        "topic": "Information Theory",
        "datatype": "Paper",
        "authors": "R. W. Hamming",
        "keywords": [
            "Error Correction",
            "Error Detection",
            "Information Theory"
        ]
    },
    {
        "name": "Estimating or propagating gradients through stochastic neurons for conditional computation",
        "url": "https://arxiv.org/abs/1308.3432",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Yoshua Bengio, Nicholas L\u00e9onard, Aaron Courville",
        "keywords": ["Backpropagation", "Deep Learning", "Gradient Estimation"]
    },
    {
        "name": "Exemplar encoder-decoder for neural conversation generation",
        "url": "https://www.aclweb.org/anthology/P18-1123/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Gaurav Pandey, Danish Contractor, Vineet Kumar, Sachindra Joshi",
        "keywords": ["Dialog", "NLP"]
    },
    {
        "name": "Expert human-level driving in gran turismo sport using deep reinforcement learning with image-based representation",
        "url": "https://arxiv.org/abs/2111.06449",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Ryuji Imamura, Takuma Seno, Kenta Kawamoto, Michael Spranger",
        "keywords": ["Reinforcement Learning"]
    },
    {
        "name": "Exploring deep recurrent models with reinforcement learning for molecule design",
        "url": "https://openreview.net/forum?id=HkcTe-bR-",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Daniel Neil, Marwin Segler, Laura Guasch, Mohamed Ahmed, Dean Plumbley, Matthew Sellwood, Nathan Brown",
        "keywords": ["Molecular Chemistry", "Reinforcement Learning"]
    },
    {
        "name": "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "url": "https://arxiv.org/abs/1910.10683",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu",
        "keywords": ["NLP", "Transformers"]
    },
    {
        "name": "Extreme compression for pre-trained transformers made simple and efficient",
        "url": "https://arxiv.org/abs/2206.01859",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Xiaoxia Wu, Zhewei Yao, Minjia Zhang, Conglong Li, Yuxiong He",
        "keywords": [
            "Compression",
            "Deep Learning",
            "Distillation",
            "Large Models",
            "Pruning",
            "Transformers"
        ]
    },
    {
        "name": "FFJORD: Free-form continuous dynamics for scalable reversible generative models",
        "url": "https://arxiv.org/abs/1810.01367",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Will Grathwohl, Ricky T. Q. Chen, Jesse Bettencourt, Ilya Sutskever, David Duvenaud",
        "keywords": ["Deep Learning", "Generative Models"]
    },
    {
        "name": "Fast abstractive summarization with reinforce-selected sentence rewriting",
        "url": "https://arxiv.org/abs/1805.11080",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Yen-Chun Chen, Mohit Bansal",
        "keywords": ["NLP", "Reinforcement Learning", "Summarization"]
    },
    {
        "name": "Fast transformer decoding: one write-head is all you need",
        "url": "https://arxiv.org/abs/1911.02150",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Noam Shazeer",
        "keywords": ["Attention Mechanism", "NLP", "Transformers"]
    },
    {
        "name": "Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning",
        "url": "https://arxiv.org/abs/2205.05638",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Haokun Liu, Derek Tam, Mohammed Muqeeth, Jay Mohta, Tenghao Huang, Mohit Bansal, Colin Raffel",
        "keywords": ["Deep Learning", "Efficient Finetuning"]
    },
    {
        "name": "Finetuned language models are zero-shot learners",
        "url": "https://arxiv.org/abs/2109.01652",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, Quoc V. Le",
        "keywords": ["NLP", "Transformers", "Zero Shot"]
    },
    {
        "name": "Flash-decoding for long-context inference",
        "url": "https://pytorch.org/blog/flash-decoding/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Tri Dao, Daniel Haziza, Francisco Massa, Grigory Sizov",
        "keywords": ["Deep Learning", "Systems", "Transformers"]
    },
    {
        "name": "FlashAttention: fast and memory-efficient exact attention with IO-awareness",
        "url": "https://arxiv.org/abs/2205.14135",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Tri Dao, Daniel Y. Fu, Stefano Ermon, Atri Rudra, Christopher R\u00e9",
        "keywords": ["Deep Learning", "Systems", "Transformers"]
    },
    {
        "name": "FlashAttention: fast transformer training with long sequences",
        "url": "https://crfm.stanford.edu/2023/01/13/flashattention.html",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Tri Dao",
        "keywords": ["Deep Learning", "Systems", "Transformers"]
    },
    {
        "name": "Flipping bits in memory without accessing them: an experimental study of DRAM disturbance errors",
        "url": "https://ieeexplore.ieee.org/document/6853210",
        "topic": "Computer Architecture",
        "datatype": "Paper",
        "authors": "Yoongu Kim, Ross Daly, Jeremie Kim, Chris Fallin, Ji Hye Lee, Donghyuk Lee, Chris Wilkerson, Konrad Lai, Onur Mutlu",
        "keywords": ["Computer Architecture", "Memory", "Security"]
    },
    {
        "name": "Foundations of NLP explained visually: beam search, how it works",
        "url": "https://towardsdatascience.com/foundations-of-nlp-explained-visually-beam-search-how-it-works-1586b9849a24",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Ketan Doshi",
        "keywords": ["Algorithms", "NLP"]
    },
    {
        "name": "Foundations of Signal Processing",
        "url": null,
        "topic": "Signal Processing",
        "datatype": "Book",
        "authors": "Martin Vetterli, Jelena Kova\u010devi\u0107, Vivek K Goyal",
        "keywords": null
    },
    {
        "name": "GLM-130B: an open bilingual pre-trained model",
        "url": "https://keg.cs.tsinghua.edu.cn/glm-130b/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "",
        "keywords": ["Large Models", "NLP", "Transformers"]
    },
    {
        "name": "GLU variants improve transformer",
        "url": "https://arxiv.org/abs/2002.05202",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Noam Shazeer",
        "keywords": ["Activation Function", "Deep Learning"]
    },
    {
        "name": "GLaM: efficient scaling of language models with mixture-of-experts",
        "url": "https://arxiv.org/abs/2112.06905",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Nan Du, Yanping Huang, Andrew M. Dai, Simon Tong, Dmitry Lepikhin, Yuanzhong Xu, Maxim Krikun, Yanqi Zhou, Adams Wei Yu, Orhan Firat, Barret Zoph, Liam Fedus, Maarten Bosma, Zongwei Zhou, Tao Wang, Yu Emma Wang, Kellie Webster, Marie Pellat, Kevin Robinson, Kathleen Meier-Hellstern, Toju Duke, Lucas Dixon, Kun Zhang, Quoc V Le, Yonghui Wu, Zhifeng Chen, Claire Cui",
        "keywords": [
            "Deep Learning",
            "Large Models",
            "Mixture of Experts",
            "Transformers"
        ]
    },
    {
        "name": "GPT-4 architecture, infrastructure, training dataset, costs, vision, MoE",
        "url": "https://www.semianalysis.com/p/gpt-4-architecture-infrastructure",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Dylan Patel, Gerald Wong",
        "keywords": [
            "Distributed Training",
            "Large Models",
            "Mixture of Experts",
            "NLP",
            "Systems",
            "Transformers"
        ]
    },
    {
        "name": "GPT-NeoX-20B: an open-source autoregressive language model",
        "url": "https://arxiv.org/abs/2204.06745",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, Michael Pieler, USVSN Sai Prashanth, Shivanshu Purohit, Laria Reynolds, Jonathan Tow, Ben Wang, Samuel Weinbach",
        "keywords": ["Large Models", "NLP", "Transformers"]
    },
    {
        "name": "GQA: training generalized multi-query transformer models from multi-head checkpoints",
        "url": "https://arxiv.org/abs/2305.13245",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Joshua Ainslie, James Lee-Thorp, Michiel de Jong, Yury Zemlyanskiy, Federico Lebr\u00f3n, Sumit Sanghai",
        "keywords": ["Attention Mechanism", "NLP", "Transformers"]
    },
    {
        "name": "Generating adversarial examples with adversarial networks",
        "url": "https://www.ijcai.org/proceedings/2018/543",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Chaowei Xiao, Bo Li, Jun-yan Zhu, Warren He, Mingyan Liu, Dawn Song",
        "keywords": [
            "Adversarial Examples",
            "Adversarial Learning",
            "Deep Learning",
            "Generative Models"
        ]
    },
    {
        "name": "Generating sentences from a continuous space",
        "url": "https://arxiv.org/abs/1511.06349",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Samuel R. Bowman, Luke Vilnis, Oriol Vinyals, Andrew M. Dai, Rafal Jozefowicz, Samy Bengio",
        "keywords": ["NLP"]
    },
    {
        "name": "Generation-augmented retrieval for open-domain question answering",
        "url": "https://arxiv.org/abs/2009.08553",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Yuning Mao, Pengcheng He, Xiaodong Liu, Yelong Shen, Jianfeng Gao, Jiawei Han, Weizhu Chen",
        "keywords": ["NLP", "Question Answering"]
    },
    {
        "name": "Generative adversarial nets",
        "url": "https://arxiv.org/abs/1406.2661",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio",
        "keywords": [
            "Adversarial Learning",
            "Deep Learning",
            "Generative Models"
        ]
    },
    {
        "name": "Genetic algorithms in search, optimization and machine learning",
        "url": null,
        "topic": "AI, DL, NLP and RL",
        "datatype": "Book",
        "authors": "David E. Goldberg",
        "keywords": null
    },
    {
        "name": "GeoMAN: multi-level attention networks for geo-sensory time series prediction",
        "url": "https://www.ijcai.org/proceedings/2018/476",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Yuxuan Liang, Songyu Ke, Junbo Zhang, Xiuwen Yi, Yu Zheng",
        "keywords": ["Deep Learning", "Spatio-Temporal", "Time Series"]
    },
    {
        "name": "Getting the most out of the NVIDIA A100 GPU with Multi-Instance GPU",
        "url": "https://developer.nvidia.com/blog/getting-the-most-out-of-the-a100-gpu-with-multi-instance-gpu/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Maggie Zhang, James Sohn, Chetan Tekur",
        "keywords": ["Deep Learning", "Systems"]
    },
    {
        "name": "Going deeper with convolutions",
        "url": "https://arxiv.org/abs/1409.4842",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich",
        "keywords": ["Computer Vision", "Image Classification"]
    },
    {
        "name": "Gradient-based hyperparameter optimization through reversible learning",
        "url": "https://arxiv.org/abs/1502.03492",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Dougal Maclaurin, David Duvenaud, Ryan P. Adams",
        "keywords": ["Deep Learning", "Meta Learning"]
    },
    {
        "name": "Graph attention networks",
        "url": "https://arxiv.org/abs/1710.10903",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Petar Veli\u010dkovi\u0107, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Li\u00f2, Yoshua Bengio",
        "keywords": ["Deep Learning", "Graph Neural Networks"]
    },
    {
        "name": "Hierarchical neural story generation",
        "url": "https://arxiv.org/abs/1805.04833",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Angela Fan, Mike Lewis, Yann Dauphin",
        "keywords": ["NLP", "Story Generation"]
    },
    {
        "name": "Hindsight: posterior-guided training of retrievers for improved open-ended generation",
        "url": "https://arxiv.org/abs/2110.07752",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Ashwin Paranjape, Omar Khattab, Christopher Potts, Matei Zaharia, Christopher D. Manning",
        "keywords": [
            "NLP",
            "Retrieval-Augmented Generation",
            "Variational Inference"
        ]
    },
    {
        "name": "HotFlip: white-box adversarial examples for text classification",
        "url": "https://arxiv.org/abs/1712.06751",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Javid Ebrahimi, Anyi Rao, Daniel Lowd, Dejing Dou",
        "keywords": ["Adversarial Examples", "NLP"]
    },
    {
        "name": "How big should my language model be?",
        "url": "https://huggingface.co/calculator/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Teven Le Scao",
        "keywords": ["Large Models", "NLP", "Scaling Laws"]
    },
    {
        "name": "How should AI systems behave, and who should decide?",
        "url": "https://openai.com/blog/how-should-ai-systems-behave",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": null,
        "keywords": ["NLP", "Safety and Alignment"]
    },
    {
        "name": "How we sped up transformer inference 100x for \ud83e\udd17 API customers",
        "url": "https://huggingface.co/blog/accelerated-inference",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": null,
        "keywords": ["Deep Learning", "Transformers"]
    },
    {
        "name": "How \ud83e\udd17 Accelerate runs very large models thanks to PyTorch",
        "url": "https://huggingface.co/blog/accelerate-large-models",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Sylvain Gugger",
        "keywords": [
            "Deep Learning",
            "Distributed Training",
            "Large Models",
            "Transformers"
        ]
    },
    {
        "name": "HyKnow: end-to-end task-oriented dialog modeling with hybrid knowledge management",
        "url": "https://arxiv.org/abs/2105.06041",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Silin Gao, Ryuichi Takanobu, Wei Peng, Qun Liu, Minlie Huang",
        "keywords": ["Dialog", "NLP"]
    },
    {
        "name": "Hyperparameter search with Transformers and Ray Tune",
        "url": "https://huggingface.co/blog/ray-tune",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": null,
        "keywords": ["Deep Learning", "Hyperparameter Search", "Transformers"]
    },
    {
        "name": "Image recognition with an adiabatic quantum computer I. mapping to quadratic unconstrained binary optimization",
        "url": "https://arxiv.org/abs/0804.4457",
        "topic": "Quantum Computing",
        "datatype": "Paper",
        "authors": "Hartmut Neven, Geordie Rose, William G. Macready",
        "keywords": ["Image Classification", "QUBO", "Quantum Computing"]
    },
    {
        "name": "Image-to-image translation with conditional generative adversarial networks",
        "url": "https://arxiv.org/abs/1611.07004",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, Alexei A. Efros",
        "keywords": null
    },
    {
        "name": "ImageNet classification using deep convolutional neural networks",
        "url": "https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton",
        "keywords": ["Computer Vision", "Image Classification"]
    },
    {
        "name": "Improving DRAM performance by parallelizing refreshes with accesses",
        "url": "https://ieeexplore.ieee.org/document/6835946",
        "topic": "Computer Architecture",
        "datatype": "Paper",
        "authors": "Kevin Kai-Wei Chang, Donghyuk Lee, Zeshan Chishti, Alaa R. Alameldeen, Chris Wilkerson, Yoongu Kim, Onur Mutlu",
        "keywords": ["Computer Architecture", "Memory", "Security", "Systems"]
    },
    {
        "name": "Improving entity linking by modeling latent relations between mentions",
        "url": "https://arxiv.org/abs/1804.10637",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Phong Le, Ivan Titov",
        "keywords": ["Entity Linking", "NLP"]
    },
    {
        "name": "Improving language models by retrieving from trillions of tokens",
        "url": "https://arxiv.org/abs/2112.04426",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, Diego de Las Casas, Aurelia Guy, Jacob Menick, Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero, Karen Simonyan, Jack W. Rae, Erich Elsen, Laurent Sifre",
        "keywords": [
            "Hallucination",
            "Information Retrieval",
            "NLP",
            "Retrieval-Augmented Generation"
        ]
    },
    {
        "name": "Improving language understanding by generative pre-training",
        "url": "https://arxiv.org/abs/2112.04426",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever",
        "keywords": ["NLP", "Retrieval-Augmented Generation"]
    },
    {
        "name": "Incredibly fast BLOOM inference with DeepSpeed and Accelerate",
        "url": "https://huggingface.co/blog/bloom-inference-pytorch-scripts",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Stas Bekman, Sylvain Gugger",
        "keywords": ["Large Models", "NLP", "Transformers"]
    },
    {
        "name": "Inference suboptimality in variational autoencoders",
        "url": "https://arxiv.org/abs/1801.03558",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Chris Cremer, Xuechen Li, David Duvenaud",
        "keywords": [
            "Approximate Inference",
            "Deep Learning",
            "Variational Inference"
        ]
    },
    {
        "name": "InfoGAN: interpretable representation learning by information maximizing generative adversarial nets",
        "url": "https://arxiv.org/abs/1606.03657",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, Pieter Abbeel",
        "keywords": [
            "Adversarial Learning",
            "Deep Learning",
            "Generative Models",
            "Information Theory"
        ]
    },
    {
        "name": "Integer optimization toolbox (minimizing polynomials over integer lattices using quantum annealing)",
        "url": "https://1qbit.com/whitepaper/integer-optimization-toolbox/",
        "topic": "Quantum Computing",
        "datatype": "Whitepaper",
        "authors": "Pooya Ronagh",
        "keywords": null
    },
    {
        "name": "Interpretable convolutional neural networks via feedforward design",
        "url": "https://arxiv.org/abs/1810.02786",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "C.-C. Jay Kuo, Min Zhang, Siyang Li, Jiali Duan, Yueru Chen",
        "keywords": ["Computer Vision"]
    },
    {
        "name": "Introducing MPT-7B: a new standard for open-source, commercially usable LLMs",
        "url": "https://www.mosaicml.com/blog/mpt-7b",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "The MosaicML NLP Team",
        "keywords": ["Large Models", "NLP", "Transformers"]
    },
    {
        "name": "Introducing Turing image super resolution: AI powered image enhancements for Microsoft Edge and Bing maps",
        "url": "https://blogs.bing.com/search-quality-insights/may-2022/Turing-Image-Super-Resolution",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": null,
        "keywords": ["Deep Learning", "Image Super Resolution"]
    },
    {
        "name": "Introducing nvFuser, a deep learning compiler for PyTorch",
        "url": "https://pytorch.org/blog/introducing-nvfuser-a-deep-learning-compiler-for-pytorch/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Christian Sarofeen, Piotr Bialecki, Jie Jiang, Kevin Stephano, Masaki Kozuki, Neal Vaidya, Stas Bekman",
        "keywords": ["Deep Learning", "Graph Fusion", "HPC Compiler", "Systems"]
    },
    {
        "name": "Introducing \ud83e\udd17 accelerate",
        "url": "https://huggingface.co/blog/accelerate-library",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Sylvain Gugger",
        "keywords": ["Deep Learning", "Distributed Training", "Large Models"]
    },
    {
        "name": "Introduction to algorithms",
        "url": null,
        "topic": "Data Structures and Algorithms",
        "datatype": "Book",
        "authors": "Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, Clifford Stein",
        "keywords": null
    },
    {
        "name": "Introduction to graph theory",
        "url": null,
        "topic": "Graph Theory",
        "datatype": "Book",
        "authors": "Robin Wilson",
        "keywords": null
    },
    {
        "name": "Introduction to probability and stochastic processes with applications",
        "url": null,
        "topic": "Probability and Stochastic Processes",
        "datatype": "Book",
        "authors": "Liliana Blanco Castaneda, Viswanathan Arunachalam, Delvamuthu Dharmaraja",
        "keywords": null
    },
    {
        "name": "Is ChatGPT 175 billion parameters? Technical analysis",
        "url": "https://orenleung.com/is-chatgpt-175-billion-parameters-technical-analysis",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Oren Leung",
        "keywords": ["NLP", "Systems"]
    },
    {
        "name": "Is the future of neural networks Sparse? An introduction (1/N)",
        "url": "https://medium.com/huggingface/is-the-future-of-neural-networks-sparse-an-introduction-1-n-d03923ecbd70",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Fran\u00e7ois Lagunas",
        "keywords": ["Deep Learning", "Sparse Matrices"]
    },
    {
        "name": "Joint reasoning on hybrid-knowledge sources for task-oriented dialog",
        "url": "https://arxiv.org/abs/2210.07295",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Mayank Mishra, Danish Contractor, Dinesh Raghu",
        "keywords": ["Dialog", "NLP"]
    },
    {
        "name": "Know what you don't know: unanswerable questions for SQuAD",
        "url": "https://arxiv.org/abs/1806.03822",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Pranav Rajpurkar, Robin Jia, Percy Liang",
        "keywords": ["NLP", "Question Answering"]
    },
    {
        "name": "Knowledge-grounded dialogue generation with pre-trained language models",
        "url": "https://arxiv.org/abs/2010.08824",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Xueliang Zhao, Wei Wu, Can Xu, Chongyang Tao, Dongyan Zhao, Rui Yan",
        "keywords": ["Dialog", "NLP"]
    },
    {
        "name": "LLM in a flash: efficient large language model inference with limited memory",
        "url": "https://arxiv.org/abs/2312.11514",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Keivan Alizadeh, Iman Mirzadeh, Dmitry Belenko, Karen Khatamifard, Minsik Cho, Carlo C Del Mundo, Mohammad Rastegari, Mehrdad Farajtabar",
        "keywords": ["Deep Learning", "Systems", "Transformers"]
    },
    {
        "name": "LLM.int8(): 8-bit matrix multiplication for transformers at scale",
        "url": "https://arxiv.org/abs/2208.07339",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Tim Dettmers, Mike Lewis, Younes Belkada, Luke Zettlemoyer",
        "keywords": ["Deep Learning", "Quantization"]
    },
    {
        "name": "Language is not all you need: aligning perception with language models",
        "url": "https://arxiv.org/abs/2302.14045",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Shaohan Huang, Li Dong, Wenhui Wang, Yaru Hao, Saksham Singhal, Shuming Ma, Tengchao Lv, Lei Cui, Owais Khan Mohammed, Barun Patra, Qiang Liu, Kriti Aggarwal, Zewen Chi, Johan Bjorck, Vishrav Chaudhary, Subhojit Som, Xia Song, Furu Wei",
        "keywords": ["Deep Learning", "Multi-modal"]
    },
    {
        "name": "Language modeling with gated convolutional networks",
        "url": "https://arxiv.org/abs/1612.08083",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Yann N. Dauphin, Angela Fan, Michael Auli, David Grangier",
        "keywords": ["Activation Function", "NLP"]
    },
    {
        "name": "Language modelling with pixels",
        "url": "https://arxiv.org/abs/2207.06991",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Phillip Rust, Jonas F. Lotz, Emanuele Bugliarello, Elizabeth Salesky, Miryam de Lhoneux, Desmond Elliott",
        "keywords": ["Computer Vision", "NLP"]
    },
    {
        "name": "Language models (mostly) know what they know",
        "url": "https://arxiv.org/abs/2207.05221",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli Tran-Johnson, Scott Johnston, Sheer El-Showk, Andy Jones, Nelson Elhage, Tristan Hume, Anna Chen, Yuntao Bai, Sam Bowman, Stanislav Fort, Deep Ganguli, Danny Hernandez, Josh Jacobson, Jackson Kernion, Shauna Kravec, Liane Lovitt, Kamal Ndousse, Catherine Olsson, Sam Ringer, Dario Amodei, Tom Brown, Jack Clark, Nicholas Joseph, Ben Mann, Sam McCandlish, Chris Olah, Jared Kaplan",
        "keywords": ["Hallucination", "NLP"]
    },
    {
        "name": "Language models are unsupervised multitask learners",
        "url": "https://openai.com/blog/better-language-models/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever",
        "keywords": ["NLP", "Transformers"]
    },
    {
        "name": "Large language models are not fair evaluators",
        "url": "https://arxiv.org/abs/2305.17926",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Peiyi Wang, Lei Li, Liang Chen, Zefan Cai, Dawei Zhu, Binghuai Lin, Yunbo Cao, Qi Liu, Tianyu Liu, Zhifang Sui",
        "keywords": ["Evaluation using LLMs", "NLP"]
    },
    {
        "name": "Layer normalization",
        "url": "http://arxiv.org/abs/1607.06450",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Jimmy Lei Ba, Jamie Ryan Kiros, Geoffrey E. Hinton",
        "keywords": ["Deep Learning", "Normalization", "Optimization"]
    },
    {
        "name": "Learning activation functions to improve deep neural networks",
        "url": "https://arxiv.org/abs/1412.6830",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Forest Agostinelli, Matthew Hoffman, Peter Sadowski, Pierre Baldi",
        "keywords": ["Deep Learning"]
    },
    {
        "name": "Learning discourse-level diversity for neural dialog models using conditional variational autoencoders",
        "url": "https://arxiv.org/abs/1703.10960",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Tiancheng Zhao, Ran Zhao, Maxine Eskenazi",
        "keywords": ["Dialog", "NLP", "Variational Inference"]
    },
    {
        "name": "Learning on a general network",
        "url": "https://papers.nips.cc/paper/9-learning-on-a-general-network",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Amir F. Atiya",
        "keywords": ["Backpropagation", "Deep Learning"]
    },
    {
        "name": "Learning representations by back-propagating errors",
        "url": "https://www.nature.com/articles/323533a0",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "David E. Rumelhart, Geoffrey E. Hinton, Ronald J. Williams",
        "keywords": ["Backpropagation", "Deep Learning"]
    },
    {
        "name": "Learning transferable visual models from natural language supervision",
        "url": "https://arxiv.org/abs/2103.00020",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever",
        "keywords": ["Computer Vision"]
    },
    {
        "name": "Learning word embeddings efficiently with noise-contrastive estimation",
        "url": "https://papers.nips.cc/paper/5165-learning-word-embeddings-efficiently-with-noise-contrastive-estimation",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Andriy Mnih, Koray Kavukcuoglu",
        "keywords": ["Embeddings", "NLP"]
    },
    {
        "name": "Lessons learned on language model safety and misuse",
        "url": "https://openai.com/blog/language-model-safety-and-misuse/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": null,
        "keywords": ["Ethical Impacts of AI", "NLP"]
    },
    {
        "name": "Lifelong language pretraining with distribution-specialized experts",
        "url": "https://arxiv.org/abs/2305.12281",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Wuyang Chen, Yanqi Zhou, Nan Du, Yanping Huang, James Laudon, Zhifeng Chen, Claire Cu",
        "keywords": [
            "Catastrophic Forgetting",
            "Deep Learning",
            "Mixture of Experts"
        ]
    },
    {
        "name": "Limits on parallel speedup for classical Ising model solvers",
        "url": "https://www.dwavesys.com/resources/white-paper/limits-on-parallel-speedup-for-classical-ising-model-solvers/",
        "topic": "Quantum Computing",
        "datatype": "Whitepaper",
        "authors": null,
        "keywords": null
    },
    {
        "name": "Linear algebra and its applications",
        "url": null,
        "topic": "Linear Algebra",
        "datatype": "Book",
        "authors": "Gilbert Strang",
        "keywords": null
    },
    {
        "name": "Linear scaling made possible with weight streaming",
        "url": "https://www.cerebras.net/blog/linear-scaling-made-possible-with-weight-streaming",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Andrew Feldman",
        "keywords": [
            "Deep Learning",
            "Distributed Training",
            "Large Models",
            "Systems"
        ]
    },
    {
        "name": "Linformer: self-attention with linear complexity",
        "url": "https://arxiv.org/abs/2006.04768",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Sinong Wang, Belinda Z. Li, Madian Khabsa, Han Fang, Hao Ma",
        "keywords": ["Attention Mechanism", "Deep Learning", "Transformers"]
    },
    {
        "name": "LoRA: Low-Rank Adaptation of large language models",
        "url": "https://arxiv.org/abs/2106.09685",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen",
        "keywords": ["Deep Learning", "Efficient Finetuning"]
    },
    {
        "name": "Long sequence modeling with XGen: a 7B LLM trained on 8K input sequence length",
        "url": "https://blog.salesforceairesearch.com/xgen/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Erik Nijkamp, Hiroaki Hayashi, Tian Xie, Congying Xia, Bo Pang, Rui Meng, Wojciech Kryscinski, Lifu Tu, Meghana Bhat, Semih Yavuz, Chen Xing, Jesse Vig, Lidiya Murakhovs'ka, Chien-Sheng Wu, Yingbo Zhou, Shafiq Rayhan Joty, Caiming Xiong, Silvio Savarese",
        "keywords": ["Long Context Length", "NLP", "Transformers"]
    },
    {
        "name": "Lost in the middle: how language models use long contexts",
        "url": "https://arxiv.org/abs/2307.03172",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, Percy Liang",
        "keywords": ["Long Context Length", "Transformers"]
    },
    {
        "name": "M6-10T: a sharing-delinking paradigm for efficient multi-trillion parameter pretraining",
        "url": "https://arxiv.org/abs/2110.03888",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Junyang Lin, An Yang, Jinze Bai, Chang Zhou, Le Jiang, Xianyan Jia, Ang Wang, Jie Zhang, Yong Li, Wei Lin, Jingren Zhou, Hongxia Yang",
        "keywords": [
            "Deep Learning",
            "Distributed Training",
            "Green AI",
            "Large Models",
            "Mixture of Experts",
            "Multi-modal",
            "Transformers"
        ]
    },
    {
        "name": "MCR-DL: mix-and-match communication runtime for deep learning",
        "url": "https://arxiv.org/abs/2303.08374",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Quentin Anthony, Ammar Ahmad Awan, Jeff Rasley, Yuxiong He, Aamir Shafi, Mustafa Abduljabbar, Hari Subramoni, Dhabaleswar Panda",
        "keywords": ["Deep Learning", "Distributed Training", "Systems"]
    },
    {
        "name": "MMCoQA: conversational question answering over text, tables and images",
        "url": "https://aclanthology.org/2022.acl-long.290/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Yongqi Li, Wenjie Li, Liqiang Nie",
        "keywords": ["Dataset", "Dialog", "NLP", "Question Answering"]
    },
    {
        "name": "MTIA v1: Meta's first-generation AI inference accelerator",
        "url": "https://ai.facebook.com/blog/meta-training-inference-accelerator-AI-MTIA/",
        "topic": "Computer Architecture",
        "datatype": "Blog",
        "authors": "Amin Firoozshahian, Olivia Wu, Joel Coburn, Roman Levenstein",
        "keywords": ["ASIC", "Deep Learning"]
    },
    {
        "name": "Machine learning",
        "url": null,
        "topic": "AI, DL, NLP and RL",
        "datatype": "Book",
        "authors": "Tom M. Mitchell",
        "keywords": null
    },
    {
        "name": "Machine learning: a probabilistic perspective",
        "url": null,
        "topic": "AI, DL, NLP and RL",
        "datatype": "Book",
        "authors": "Kevin P. Murphy",
        "keywords": null
    },
    {
        "name": "Making DeepSpeed ZeRO run efficiently on more-affordable hardware",
        "url": "https://www.amazon.science/blog/making-deepspeed-zero-run-efficiently-on-more-affordable-hardware",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Justin Chiu, Shuai Zheng",
        "keywords": ["Deep Learning", "Distributed Training", "Large Models"]
    },
    {
        "name": "Making deep learning go brrrr from first principles",
        "url": "https://horace.io/brrr_intro.html",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Horace He",
        "keywords": ["Deep Learning", "Systems"]
    },
    {
        "name": "Mask & focus: conversation modelling by learning concepts",
        "url": "https://arxiv.org/abs/2003.04976",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Gaurav Pandey, Dinesh Raghu, Sachindra Joshi",
        "keywords": ["Dialog", "NLP"]
    },
    {
        "name": "Matrix analysis and applied linear algebra",
        "url": null,
        "topic": "Linear Algebra",
        "datatype": "Book",
        "authors": "Carl D. Meyer",
        "keywords": null
    },
    {
        "name": "Maximizing communication efficiency for large-scale training via 0/1 Adam",
        "url": "https://arxiv.org/abs/2202.06009",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Yucheng Lu, Conglong Li, Minjia Zhang, Christopher De Sa, Yuxiong He",
        "keywords": ["Deep Learning", "Distributed Training"]
    },
    {
        "name": "Measure theory",
        "url": null,
        "topic": "Measure Theory",
        "datatype": "Book",
        "authors": "Donald L. Cohn",
        "keywords": null
    },
    {
        "name": "MegaBlocks: efficient sparse training with mixture-of-experts",
        "url": "https://arxiv.org/abs/2211.15841",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Trevor Gale, Deepak Narayanan, Cliff Young, Matei Zaharia",
        "keywords": ["Deep Learning", "Mixture of Experts", "Systems"]
    },
    {
        "name": "Megatron-LM: training multi-billion parameter language models using model parallelism",
        "url": "https://arxiv.org/abs/1909.08053",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, Bryan Catanzaro",
        "keywords": [
            "Deep Learning",
            "Distributed Training",
            "Large Models",
            "Systems",
            "Transformers"
        ]
    },
    {
        "name": "Memory performance attacks: denial of memory service in multi-core systems",
        "url": "https://www.usenix.org/conference/16th-usenix-security-symposium/memory-performance-attacks-denial-memory-service-multi",
        "topic": "Computer Architecture",
        "datatype": "Paper",
        "authors": "Thomas Moscibroda, Onur Mutlu",
        "keywords": ["Computer Architecture", "Memory", "Security"]
    },
    {
        "name": "Memory scaling: a systems architecture perspective",
        "url": "https://ieeexplore.ieee.org/document/6582088",
        "topic": "Computer Architecture",
        "datatype": "Paper",
        "authors": "Onur Mutlu",
        "keywords": ["Computer Architecture", "Memory"]
    },
    {
        "name": "Memory-efficient pipeline-parallel DNN training",
        "url": "https://arxiv.org/abs/2006.09503",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Deepak Narayanan, Amar Phanishayee, Kaiyu Shi, Xie Chen, Matei Zaharia",
        "keywords": [
            "Distributed Training",
            "Large Models",
            "NLP",
            "Systems",
            "Transformers"
        ]
    },
    {
        "name": "Millicode in an IBM zSeries processor",
        "url": "https://ieeexplore.ieee.org/document/5388884",
        "topic": "Computer Architecture",
        "datatype": "Paper",
        "authors": "L. C. Heller, M. S. Farrell",
        "keywords": ["Computer Architecture"]
    },
    {
        "name": "MinTL: minimalist transfer learning for task-oriented dialogue systems",
        "url": "https://arxiv.org/abs/2009.12005",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Zhaojiang Lin, Andrea Madotto, Genta Indra Winata, Pascale Fung",
        "keywords": ["Dialog", "NLP"]
    },
    {
        "name": "Mix and match: learning-free controllable text generation using energy language models",
        "url": "https://arxiv.org/abs/2203.13299",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Fatemehsadat Mireshghallah, Kartik Goyal, Taylor Berg-Kirkpatrick",
        "keywords": ["Energy-based Models", "NLP"]
    },
    {
        "name": "Mixed precision training",
        "url": "https://arxiv.org/abs/1710.03740",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Paulius Micikevicius, Sharan Narang, Jonah Alben, Gregory Diamos, Erich Elsen, David Garcia, Boris Ginsburg, Michael Houston, Oleksii Kuchaiev, Ganesh Venkatesh, Hao Wu",
        "keywords": ["Deep Learning", "Large Models"]
    },
    {
        "name": "Mixture-of-Experts meets instruction tuning: a winning combination for large language models",
        "url": "https://arxiv.org/abs/2305.14705",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Sheng Shen, Le Hou, Yanqi Zhou, Nan Du, Shayne Longpre, Jason Wei, Hyung Won Chung, Barret Zoph, William Fedus, Xinyun Chen, Tu Vu, Yuexin Wu, Wuyang Chen, Albert Webson, Yunxuan Li, Vincent Zhao, Hongkun Yu, Kurt Keutzer, Trevor Darrell, Denny Zhou",
        "keywords": ["Instruction Finetuning", "Mixture of Experts", "NLP"]
    },
    {
        "name": "Mode matching in GANs through latent space learning and inversion",
        "url": "https://arxiv.org/abs/1811.03692",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Deepak Mishra, Prathosh A. P., Aravind Jayendran, Varun Srivastava, Santanu Chaudhury",
        "keywords": [
            "Adversarial Learning",
            "Deep Learning",
            "Generative Models"
        ]
    },
    {
        "name": "Multi-level memory for task oriented dialogs",
        "url": "https://arxiv.org/abs/1810.10647",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Revanth Reddy, Danish Contractor, Dinesh Raghu, Sachindra Joshi",
        "keywords": ["Dialog", "NLP"]
    },
    {
        "name": "MultiWOZ - A large-scale multi-domain Wizard-of-Oz dataset for task-oriented dialogue modelling",
        "url": "https://arxiv.org/abs/1810.00278",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Pawe\u0142 Budzianowski, Tsung-Hsien Wen, Bo-Hsiang Tseng, I\u00f1igo Casanueva, Stefan Ultes, Osman Ramadan, Milica Ga\u0161i\u0107",
        "keywords": ["Dataset", "Dialog", "NLP"]
    },
    {
        "name": "Multitask prompt tuning enables parameter-efficient transfer learning",
        "url": "https://openreview.net/forum?id=Nk2pDtuhTq",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Zhen Wang, Rameswar Panda, Leonid Karlinsky, Rogerio Feris, Huan Sun, Yoon Kim",
        "keywords": ["Efficient Finetuning", "NLP"]
    },
    {
        "name": "Mutual information neural estimation",
        "url": "https://arxiv.org/abs/1801.04062",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Mohamed Ishmael Belghazi, Aristide Baratin, Sai Rajeswar, Sherjil Ozair, Yoshua Bengio, Aaron Courville, R Devon Hjelm",
        "keywords": ["Deep Learning", "Information Theory"]
    },
    {
        "name": "NeMo: a toolkit for building AI applications using neural modules",
        "url": "https://arxiv.org/abs/1909.09577",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Oleksii Kuchaiev, Jason Li, Huyen Nguyen, Oleksii Hrinchuk, Ryan Leary, Boris Ginsburg, Samuel Kriman, Stanislav Beliaev, Vitaly Lavrukhin, Jack Cook, Patrice Castonguay, Mariya Popova, Jocelyn Huang, Jonathan M. Cohen",
        "keywords": ["Deep Learning", "Distributed Training", "Large Models"]
    },
    {
        "name": "Neural GPUs learn algorithms",
        "url": "https://arxiv.org/abs/1511.08228",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "\u0141ukasz Kaiser, Ilya Sutskever",
        "keywords": ["Deep Learning", "Theory of Computation"]
    },
    {
        "name": "Neural network methods for natural language processing",
        "url": null,
        "topic": "AI, DL, NLP and RL",
        "datatype": "Book",
        "authors": "Yaov Goldberg",
        "keywords": null
    },
    {
        "name": "Neural networks and physical systems with emergent collective computational abilities",
        "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC346238/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "J. J. Hopfield",
        "keywords": ["Biology", "Deep Learning", "Energy-based Models"]
    },
    {
        "name": "Neural networks for pattern recognition",
        "url": null,
        "topic": "AI, DL, NLP and RL",
        "datatype": "Book",
        "authors": "Christopher M. Bishop",
        "keywords": null
    },
    {
        "name": "Neural ordinary differential equations",
        "url": "https://arxiv.org/abs/1806.07366",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Ricky T. Q. Chen, Yulia Rubanova, Jesse Bettencourt, David Duvenaud",
        "keywords": ["Deep Learning", "Differential Equations"]
    },
    {
        "name": "OPT: open pre-trained transformer language models",
        "url": "https://arxiv.org/abs/2205.01068",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang, Luke Zettlemoyer",
        "keywords": ["Large Models", "NLP", "Transformers"]
    },
    {
        "name": "Obfuscated gradients give a false sense of security: circumventing defenses to adversarial examples",
        "url": "https://arxiv.org/abs/1802.00420",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Anish Athalye, Nicholas Carlini, David Wagner",
        "keywords": ["Adversarial Examples", "Deep Learning"]
    },
    {
        "name": "OctoPack: instruction tuning code large language models",
        "url": "https://arxiv.org/abs/2308.07124",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Niklas Muennighoff, Qian Liu, Armel Zebaze, Qinkai Zheng, Binyuan Hui, Terry Yue Zhuo, Swayam Singh, Xiangru Tang, Leandro von Werra, Shayne Longpre",
        "keywords": ["AI for code", "Instruction Finetuning", "NLP"]
    },
    {
        "name": "On the convergence of Adam and beyond",
        "url": "https://arxiv.org/abs/1904.09237",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Sashank J. Reddi, Satyen Kale, Sanjiv Kumar",
        "keywords": ["Convergence", "Deep Learning", "Optimization"]
    },
    {
        "name": "On the power of neural networks for solving hard problems",
        "url": "https://papers.nips.cc/paper/70-on-the-power-of-neural-networks-for-solving-hard-problems",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Jehoshua Bruck, Joseph W. Goodman",
        "keywords": ["Deep Learning", "NP-Hard"]
    },
    {
        "name": "One model to learn them all",
        "url": "https://arxiv.org/abs/1706.05137",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Lukasz Kaiser, Aidan N. Gomez, Noam Shazeer, Ashish Vaswani, Niki Parmar, Llion Jones, Jakob Uszkoreit",
        "keywords": ["Deep Learning", "Multi-modal"]
    },
    {
        "name": "Open domain question answering over tables via dense retrieval",
        "url": "https://arxiv.org/abs/2103.12011",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Jonathan Herzig, Thomas M\u00fcller, Syrine Krichene, Julian Eisenschlos",
        "keywords": ["NLP", "Question Answering"]
    },
    {
        "name": "Open question answering over tables and text",
        "url": "https://openreview.net/forum?id=MmCRswl1UYl",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Wenhu Chen, Ming-Wei Chang, Eva Schlinger, William Yang Wang, William W. Cohen",
        "keywords": ["NLP", "Question Answering"]
    },
    {
        "name": "Optimal brain compression: a framework for accurate post-training quantization and pruning",
        "url": "https://arxiv.org/abs/2208.11580",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Elias Frantar, Sidak Pal Singh, Dan Alistarh",
        "keywords": ["Deep Learning", "Pruning", "Quantization"]
    },
    {
        "name": "Optimal perceptual inference",
        "url": "https://www.researchgate.net/publication/260869405_Optimal_perceptual_inference",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Geoffrey E. Hinton, Terrence J. Sejnowski",
        "keywords": ["Deep Learning", "Energy-based Models"]
    },
    {
        "name": "Optimization story: Bloom inference",
        "url": "https://huggingface.co/blog/bloom-inference-optimization",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Nicolas Patry",
        "keywords": ["Deep Learning", "Large Models", "Transformers"]
    },
    {
        "name": "Outer product-based neural collaborative filtering",
        "url": "https://arxiv.org/abs/1808.03912",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Xiangnan He, Xiaoyu Du, Xiang Wang, Feng Tian, Jinhui Tang, Tat-Seng Chua",
        "keywords": [
            "Collaborative Filtering",
            "Deep Learning",
            "Recommender Systems"
        ]
    },
    {
        "name": "Outrageously large neural networks: the sparsely-gated mixture-of-experts layer",
        "url": "https://arxiv.org/abs/1701.06538",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, Jeff Dean",
        "keywords": ["Deep Learning", "Mixture of Experts"]
    },
    {
        "name": "Overcoming oscillations in quantization-aware training",
        "url": "https://arxiv.org/abs/2203.11086",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Markus Nagel, Marios Fournarakis, Yelysei Bondarenko, Tijmen Blankevoort",
        "keywords": ["Deep Learning", "Quantization"]
    },
    {
        "name": "PAL: Program-aided language models",
        "url": "https://arxiv.org/abs/2211.10435",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, Graham Neubig",
        "keywords": ["Mathematical Reasoning", "NLP"]
    },
    {
        "name": "PaLM: scaling language modeling with pathways",
        "url": "https://arxiv.org/abs/2204.02311",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, Noah Fiedel",
        "keywords": [
            "Distributed Training",
            "Large Models",
            "NLP",
            "Transformers"
        ]
    },
    {
        "name": "Parallel context windows improve in-context learning of large language models",
        "url": "https://arxiv.org/abs/2212.10947",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Nir Ratner, Yoav Levine, Yonatan Belinkov, Ori Ram, Inbal Magar, Omri Abend, Ehud Karpas, Amnon Shashua, Kevin Leyton-Brown, Yoav Shoham",
        "keywords": ["In Context Learning", "Long Context Length", "NLP"]
    },
    {
        "name": "Partitioning optimization problems for hybrid classical/quantum execution",
        "url": "https://docs.ocean.dwavesys.com/projects/qbsolv/en/latest/_downloads/bd15a2d8f32e587e9e5997ce9d5512cc/qbsolv_techReport.pdf",
        "topic": "Quantum Computing",
        "datatype": "Whitepaper",
        "authors": "Michael Booth, Steven P. Reinhardt, Aidan Roy",
        "keywords": null
    },
    {
        "name": "Pattern classification",
        "url": null,
        "topic": "AI, DL, NLP and RL",
        "datatype": "Book",
        "authors": "Richard O. Duda, Peter E. Hart, David G. Stork",
        "keywords": null
    },
    {
        "name": "Pattern recognition and machine learning",
        "url": null,
        "topic": "AI, DL, NLP and RL",
        "datatype": "Book",
        "authors": "Christopher M. Bishop",
        "keywords": null
    },
    {
        "name": "Perceptual losses for real-time style transfer and super-resolution",
        "url": "https://arxiv.org/abs/1603.08155",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Justin Johnson, Alexandre Alahi, Li Fei-Fei",
        "keywords": ["Computer Vision", "Image Super Resolution"]
    },
    {
        "name": "Personalizing dialogue agents: I have a dog, do you have pets too?",
        "url": "https://arxiv.org/abs/1801.07243",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, Jason Weston",
        "keywords": ["Dialog", "NLP"]
    },
    {
        "name": "Phase-functioned neural networks for character control",
        "url": "https://dl.acm.org/citation.cfm?id=3073663",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Daniel Holden, Taku Komura, Jun Saito",
        "keywords": ["Computer Graphics", "Deep Learning"]
    },
    {
        "name": "Playing Atari with deep reinforcement learning",
        "url": "https://arxiv.org/abs/1312.5602",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, Martin Riedmiller",
        "keywords": ["Reinforcement Learning"]
    },
    {
        "name": "Polynomial-time algorithms for prime factorization and discrete logarithms on a quantum computer",
        "url": "https://arxiv.org/abs/quant-ph/9508027",
        "topic": "Quantum Computing",
        "datatype": "Paper",
        "authors": "Peter W. Shor",
        "keywords": ["Quantum Algorithms", "Quantum Computing"]
    },
    {
        "name": "Pre-train, prompt, and predict: a systematic survey of prompting methods in natural language processing",
        "url": "https://arxiv.org/abs/2107.13586",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, Graham Neubig",
        "keywords": ["Efficient Finetuning", "Few Shot", "NLP", "Prompting"]
    },
    {
        "name": "Prefix-tuning: optimizing continuous prompts for generation",
        "url": "https://arxiv.org/abs/2101.00190",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Xiang Lisa Li, Percy Liang",
        "keywords": ["Efficient Finetuning", "Few Shot", "NLP"]
    },
    {
        "name": "Principles of traditional animation applied to 3D computer animation",
        "url": "https://dl.acm.org/doi/10.1145/37402.37407",
        "topic": "Computer Graphics",
        "datatype": "Paper",
        "authors": "John Lasseter",
        "keywords": ["Animation", "Computer Graphics"]
    },
    {
        "name": "Probabilistic cloning and identification of linearly independent quantum states",
        "url": "https://arxiv.org/abs/quant-ph/9804064",
        "topic": "Quantum Computing",
        "datatype": "Paper",
        "authors": "Lu-Ming Duan, Guang-Can Guo",
        "keywords": ["Cloning", "Quantum Computing"]
    },
    {
        "name": "Probabilistic latent semantic analysis",
        "url": "https://arxiv.org/abs/1301.6705",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Thomas Hofmann",
        "keywords": ["Information Retrieval", "NLP"]
    },
    {
        "name": "Programming with D-Wave: map coloring problem",
        "url": "https://www.dwavesys.com/resources/white-paper/programming-with-d-wave-map-coloring-problem/",
        "topic": "Quantum Computing",
        "datatype": "Whitepaper",
        "authors": "E. D. Dahl",
        "keywords": null
    },
    {
        "name": "Progressive growing of GANs from improved quality, stability and variation",
        "url": "https://arxiv.org/abs/1710.10196",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Tero Karras, Timo Aila, Samuli Laine, Jaakko Lehtinen",
        "keywords": [
            "Adversarial Learning",
            "Deep Learning",
            "Generative Models"
        ]
    },
    {
        "name": "Prompting with pseudo-code instructions",
        "url": "https://arxiv.org/abs/2305.11790",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Mayank Mishra, Prince Kumar, Riyaz Bhat, Rudra Murthy V, Danish Contractor, Srikanth Tamilselvam",
        "keywords": ["NLP", "Prompting"]
    },
    {
        "name": "PullNet: open domain question answering with iterative retrieval on knowledge bases and text",
        "url": "https://arxiv.org/abs/1904.09537",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Haitian Sun, Tania Bedrax-Weiss, William Cohen",
        "keywords": ["NLP", "Question Answering"]
    },
    {
        "name": "PyTorch trace analysis for the masses",
        "url": "https://pytorch.org/blog/trace-analysis-for-masses/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Anupam Bhatnagar, Xizhou Feng, Brian Coutinho, Yifan Liu, Sung-Han Lin, Louis Feng, and Yuzhen Huang",
        "keywords": ["Deep Learning", "Systems"]
    },
    {
        "name": "Q-BERT: Hessian based ultra low precision quantization of BERT",
        "url": "https://arxiv.org/abs/1909.05840",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Sheng Shen, Zhen Dong, Jiayu Ye, Linjian Ma, Zhewei Yao, Amir Gholami, Michael W. Mahoney, Kurt Keutzer",
        "keywords": ["NLP", "Quantization"]
    },
    {
        "name": "Quantum computation and quantum information",
        "url": null,
        "topic": "Quantum Computing",
        "datatype": "Book",
        "authors": "Michael A. Nielsen, Isaac L. Chuang",
        "keywords": null
    },
    {
        "name": "Quantum computing: a gentle introduction",
        "url": null,
        "topic": "Quantum Computing",
        "datatype": "Book",
        "authors": "Eleanor Rieffel, Wolfgang Polak",
        "keywords": null
    },
    {
        "name": "Quantum performance evaluation: a short reading list",
        "url": "https://www.dwavesys.com/resources/white-paper/quantum-performance-evaluation-a-short-reading-list/",
        "topic": "Quantum Computing",
        "datatype": "Whitepaper",
        "authors": "",
        "keywords": null
    },
    {
        "name": "Quantum theory, the Church-Turing principle and the universal quantum computer",
        "url": "https://royalsocietypublishing.org/doi/10.1098/rspa.1985.0070",
        "topic": "Quantum Computing",
        "datatype": "Paper",
        "authors": "David Deutsch",
        "keywords": ["Quantum Computing", "Theory of Computation"]
    },
    {
        "name": "RAIDR: Retention-Aware Intelligent DRAM Refresh",
        "url": "https://dl.acm.org/doi/10.5555/2337159.2337161",
        "topic": "Computer Architecture",
        "datatype": "Paper",
        "authors": "Jamie Liu, Ben Jaiyen, Richard Veras, Onur Mutlu",
        "keywords": ["Computer Architecture", "Memory"]
    },
    {
        "name": "REALM: Retrieval-augmented language model pretraining",
        "url": "https://arxiv.org/abs/2002.08909",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, Ming-Wei Chang",
        "keywords": [
            "Information Retrieval",
            "NLP",
            "Retrieval-Augmented Generation"
        ]
    },
    {
        "name": "R^{3}Net: recurrent residual refinement network for saliency detection",
        "url": "https://www.ijcai.org/proceedings/2018/95",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Zijun Deng, Xiaowei Hu, Lei Zhu, Xuemiao Xu, Jing Qin, Guoqiang Han, Pheng-Ann Heng",
        "keywords": ["Computer Vision", "Saliency Detection"]
    },
    {
        "name": "Rapid solution of problems by quantum computation",
        "url": "https://royalsocietypublishing.org/doi/abs/10.1098/rspa.1992.0167",
        "topic": "Quantum Computing",
        "datatype": "Paper",
        "authors": "David Deutsche, Richard Jozsa",
        "keywords": ["Quantum Algorithms", "Quantum Computing"]
    },
    {
        "name": "ReLoRA: high-rank training through low-rank updates",
        "url": "https://arxiv.org/abs/2307.05695",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Vladislav Lialin, Namrata Shivagunde, Sherin Muckatira, Anna Rumshisky",
        "keywords": ["Deep Learning", "Efficient Finetuning"]
    },
    {
        "name": "Reading Wikipedia to answer open-domain questions",
        "url": "https://arxiv.org/abs/1704.00051",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Danqi Chen, Adam Fisch, Jason Weston, Antoine Bordes",
        "keywords": ["NLP", "Question Answering"]
    },
    {
        "name": "Recurrent models of visual attention",
        "url": "https://arxiv.org/abs/1406.6247",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Volodymyr Mnih, Nicolas Heess, Alex Graves, Koray Kavukcuoglu",
        "keywords": null
    },
    {
        "name": "Reducing activation recomputation in large transformer models",
        "url": "https://arxiv.org/abs/2205.05198",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Vijay Korthikanti, Jared Casper, Sangkug Lym, Lawrence McAfee, Michael Andersch, Mohammad Shoeybi, Bryan Catanzaro",
        "keywords": [
            "Deep Learning",
            "Distributed Training",
            "Large Models",
            "Transformers"
        ]
    },
    {
        "name": "Regularizing and optimizing LSTM language models",
        "url": "https://arxiv.org/abs/1708.02182",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Stephen Merity, Nitish Shirish Keskar, Richard Socher",
        "keywords": ["Deep Learning", "Optimization", "Regularization"]
    },
    {
        "name": "Reinforcement Learning: An Introduction",
        "url": null,
        "topic": "AI, DL, NLP and RL",
        "datatype": "Book",
        "authors": "Richard S. Sutton, Andrew G. Barto",
        "keywords": null
    },
    {
        "name": "Restricted Boltzmann machines for collaborative filtering",
        "url": "https://dl.acm.org/citation.cfm?doid=1273496.1273596",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Ruslan Salakhutdinov, Andriy Mnih, Geoffrey Hinton",
        "keywords": [
            "Boltzmann Machines",
            "Collaborative Filtering",
            "Deep Learning",
            "Energy-based Models",
            "Recommender Systems"
        ]
    },
    {
        "name": "Retrieval augmentation reduces hallucination in conversation",
        "url": "https://arxiv.org/abs/2104.07567",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, Jason Weston",
        "keywords": [
            "Dialog",
            "Hallucination",
            "NLP",
            "Retrieval-Augmented Generation"
        ]
    },
    {
        "name": "Retrieval-augmented generation for knowledge-intensive NLP tasks",
        "url": "https://arxiv.org/abs/2005.11401",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K\u00fcttler, Mike Lewis, Wen-tau Yih, Tim Rockt\u00e4schel, Sebastian Riedel, Douwe Kiela",
        "keywords": [
            "Hallucination",
            "Information Retrieval",
            "NLP",
            "Retrieval-Augmented Generation"
        ]
    },
    {
        "name": "Revisiting classifier two-sample tests",
        "url": "https://arxiv.org/abs/1610.06545",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "David Lopez-Paz, Maxime Oquab",
        "keywords": ["Deep Learning", "Unsupervised Learning"]
    },
    {
        "name": "RoBERTa: a robustly optimized BERT pretraining approach",
        "url": "https://arxiv.org/abs/1907.11692",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov",
        "keywords": ["NLP", "Transformers"]
    },
    {
        "name": "RoFormer: enhanced transformer with rotary position embedding",
        "url": "https://arxiv.org/abs/2104.09864",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, Yunfeng Liu",
        "keywords": ["NLP", "Position Embeddings", "Transformers"]
    },
    {
        "name": "SOLAR 10.7B: scaling large language models with simple yet effective depth up-scaling",
        "url": "https://arxiv.org/abs/2312.15166",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Dahyun Kim, Chanjun Park, Sanghoon Kim, Wonsung Lee, Wonho Song, Yunsu Kim, Hyeonwoo Kim, Yungi Kim, Hyeonju Lee, Jihoo Kim, Changbae Ahn, Seonghoon Yang, Sukyung Lee, Hyunbyung Park, Gyoungjin Gim, Mikyoung Cha, Hwalsuk Lee, Sunghun Kim",
        "keywords": ["Model Upcycling", "NLP", "Transformers"]
    },
    {
        "name": "SOLOIST: building task bots at scale with transfer learning and machine teaching",
        "url": "https://arxiv.org/abs/2005.05298",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Baolin Peng, Chunyuan Li, Jinchao Li, Shahin Shayandeh, Lars Liden, Jianfeng Gao",
        "keywords": ["Dialog", "Few Shot", "NLP", "Transfer Learning"]
    },
    {
        "name": "SantaCoder: don't reach for the stars!",
        "url": "https://arxiv.org/abs/2301.03988",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher Akiki, Carlos Munoz Ferrandis, Niklas Muennighoff, Mayank Mishra, Alex Gu, Manan Dey, Logesh Kumar Umapathi, Carolyn Jane Anderson, Yangtian Zi, Joel Lamy Poirier, Hailey Schoelkopf, Sergey Troshin, Dmitry Abulkhanov, Manuel Romero, Michael Lappert, Francesco De Toni, Bernardo Garc\u00eda del R\u00edo, Qian Liu, Shamik Bose, Urvashi Bhattacharyya, Terry Yue Zhuo, Ian Yu, Paulo Villegas, Marco Zocca, Sourab Mangrulkar, David Lansky, Huu Nguyen, Danish Contractor, Luis Villa, Jia Li, Dzmitry Bahdanau, Yacine Jernite, Sean Hughes, Daniel Fried, Arjun Guha, Harm de Vries, Leandro von Werra",
        "keywords": [
            "AI for code",
            "Distributed Training",
            "Large Models",
            "Transformers"
        ]
    },
    {
        "name": "Scaling PyTorch FSDP for training foundation Models on IBM cloud",
        "url": "https://pytorch.org/blog/scaling-pytorch-fsdp-for-training-foundation-models-on-ibm-cloud/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Linsong Chu, Less Wright, Hamid Shojanazeri, Sophia Wen, Raghu Ganti, Geeta Chauhan",
        "keywords": ["Distributed Training", "Large Models", "Systems"]
    },
    {
        "name": "Scaling instruction-finetuned language models",
        "url": "https://arxiv.org/abs/2210.11416",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Alex Castro-Ros, Marie Pellat, Kevin Robinson, Dasha Valter, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, Jason Wei",
        "keywords": ["Instruction Finetuning", "NLP"]
    },
    {
        "name": "Scaling transformer to 1M tokens and beyond with RMT",
        "url": "https://arxiv.org/abs/2304.11062",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Aydar Bulatov, Yuri Kuratov, Mikhail S. Burtsev",
        "keywords": ["Long Context Length", "NLP"]
    },
    {
        "name": "Self-instruct: aligning language model with self generated instructions",
        "url": "https://arxiv.org/abs/2212.10560",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, Hannaneh Hajishirzi",
        "keywords": ["Instruction Finetuning", "NLP"]
    },
    {
        "name": "Self-normalizing neural networks",
        "url": "https://arxiv.org/abs/1706.02515",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "G\u00fcnter Klambauer, Thomas Unterthiner, Andreas Mayr, Sepp Hochreiter",
        "keywords": ["Activation Function", "Deep Learning", "Normalization"]
    },
    {
        "name": "Semantically equivalent adversarial rules for debugging NLP models",
        "url": "https://aclanthology.org/P18-1079/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Marco Tulio Ribeiro, Sameer Singh, Carlos Guestrin",
        "keywords": ["NLP"]
    },
    {
        "name": "Seq2seq model and the exposure bias problem",
        "url": "https://medium.com/analytics-vidhya/seq2seq-model-and-the-exposure-bias-problem-962bb5607097",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Aditya Mohanty",
        "keywords": ["Generative Models", "NLP"]
    },
    {
        "name": "Sequence parallelism: long sequence training from system perspective",
        "url": "https://arxiv.org/abs/2105.13120",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Shenggui Li, Fuzhao Xue, Chaitanya Baranwal, Yongbin Li, Yang You",
        "keywords": [
            "Deep Learning",
            "Distributed Training",
            "Long Context Length",
            "Systems"
        ]
    },
    {
        "name": "Sequential latent knowledge selection for knowledge-grounded dialogue",
        "url": "https://arxiv.org/abs/2002.07510",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Byeongchang Kim, Jaewoo Ahn, Gunhee Kim",
        "keywords": ["Dialog", "NLP", "Variational Inference"]
    },
    {
        "name": "Signals and systems",
        "url": null,
        "topic": "Signal Processing",
        "datatype": "Book",
        "authors": "Alan V. Oppenheim",
        "keywords": null
    },
    {
        "name": "Simple and effective multi-paragraph reading comprehension",
        "url": "https://arxiv.org/abs/1710.10723",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Christopher Clark, Matt Gardner",
        "keywords": ["NLP", "Reading Comprehension"]
    },
    {
        "name": "SmoothQuant: accurate and efficient post-training quantization for large language models",
        "url": "https://arxiv.org/abs/2211.10438",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Guangxuan Xiao, Ji Lin, Mickael Seznec, Julien Demouth, Song Han",
        "keywords": [
            "Deep Learning",
            "Large Models",
            "Quantization",
            "Transformers"
        ]
    },
    {
        "name": "Soft filter pruning for accelerating deep convolutional neural networks",
        "url": "https://arxiv.org/abs/1808.06866",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Yang He, Guoliang Kang, Xuanyi Dong, Yanwei Fu, Yi Yang",
        "keywords": ["Deep Learning", "Pruning"]
    },
    {
        "name": "Solving quantitative reasoning problems with language models",
        "url": "https://arxiv.org/abs/2206.14858",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, Yuhuai Wu, Behnam Neyshabur, Guy Gur-Ari, Vedant Misra",
        "keywords": ["Large Models", "NLP", "Transformers"]
    },
    {
        "name": "Spatial temporal graph convolutional networks for skeleton-based action recognition",
        "url": "https://arxiv.org/abs/1801.07455",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Sijie Yan, Yuanjun Xiong, Dahua Lin",
        "keywords": [
            "Deep Learning",
            "Graph Neural Networks",
            "Spatio-Temporal"
        ]
    },
    {
        "name": "Spatio-temporal graph convolutional networks: a deep learning framework for traffic forecasting",
        "url": "https://arxiv.org/abs/1709.04875",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Bing Yu, Haoteng Yin, Zhanxing Zhu",
        "keywords": [
            "Deep Learning",
            "Graph Neural Networks",
            "Spatio-Temporal",
            "Time Series"
        ]
    },
    {
        "name": "Spectral normalization for generative adversarial networks",
        "url": "https://arxiv.org/abs/1802.05957",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Takeru Miyato, Toshiki Kataoka, Masanori Koyama, Yuichi Yoshida",
        "keywords": ["Adversarial Learning", "Deep Learning"]
    },
    {
        "name": "Speech and language processing",
        "url": null,
        "topic": "AI, DL, NLP and RL",
        "datatype": "Book",
        "authors": "Daniel Jurafsky, James H. Martin",
        "keywords": null
    },
    {
        "name": "Stall-time fair memory access scheduling for chip multiprocessors",
        "url": "https://ieeexplore.ieee.org/document/4408252",
        "topic": "Computer Architecture",
        "datatype": "Paper",
        "authors": "Onur Mutlu, Thomas Moscibroda",
        "keywords": ["Computer Architecture", "Memory"]
    },
    {
        "name": "StarCoder: may the source be with you!",
        "url": "https://arxiv.org/abs/2305.06161",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadorj, Joel Lamy-Poirier, Jo\u00e3o Monteiro, Oleh Shliazhko, Nicolas Gontier, Nicholas Meade, Armel Zebaze, Ming-Ho Yee, Logesh Kumar Umapathi, Jian Zhu, Benjamin Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy, Jason Stillerman, Siva Sankalp Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan Zhang, Nour Fahmy, Urvashi Bhattacharyya, Wenhao Yu, Swayam Singh, Sasha Luccioni, Paulo Villegas, Maxim Kunakov, Fedor Zhdanov, Manuel Romero, Tony Lee, Nadav Timor, Jennifer Ding, Claire Schlesinger, Hailey Schoelkopf, Jan Ebert, Tri Dao, Mayank Mishra, Alex Gu, Jennifer Robinson, Carolyn Jane Anderson, Brendan Dolan-Gavitt, Danish Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos Mu\u00f1oz Ferrandis, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, Harm de Vries",
        "keywords": ["AI for code", "Large Models", "NLP", "Transformers"]
    },
    {
        "name": "Sticking the landing: simple, lower-variance gradient estimators for variational inference",
        "url": "https://arxiv.org/abs/1703.09194",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Geoffrey Roeder, Yuhuai Wu, David K. Duvenaud",
        "keywords": [
            "Deep Learning",
            "Gradient Estimation",
            "Variational Inference"
        ]
    },
    {
        "name": "StitchNet: composing neural networks from pre-trained fragments",
        "url": "https://arxiv.org/abs/2301.01947",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Surat Teerapittayanon, Marcus Comiter, Brad McDanel, H.T. Kung",
        "keywords": ["Deep Learning", "Growing Neural Networks"]
    },
    {
        "name": "Stochastic hyperparameter optimization through hypernetworks",
        "url": "https://arxiv.org/abs/1802.09419",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Jonathan Lorraine, David Duvenaud",
        "keywords": ["Deep Learning", "Meta Learning"]
    },
    {
        "name": "Strategies for teaching layered networks classification tasks",
        "url": "https://papers.nips.cc/paper/85-strategies-for-teaching-layered-networks-classification-tasks",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Ben S. Wittner, John S. Denker",
        "keywords": ["Deep Learning"]
    },
    {
        "name": "Structured prompting: scaling in-context learning to 1,000 examples",
        "url": "https://arxiv.org/abs/2212.06713",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Yaru Hao, Yutao Sun, Li Dong, Zhixiong Han, Yuxian Gu, Furu Wei",
        "keywords": ["Deep Learning", "In Context Learning"]
    },
    {
        "name": "Style transfer from non-parallel text by cross-alignment",
        "url": "https://arxiv.org/abs/1705.09655",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Tianxiao Shen, Tao Lei, Regina Barzilay, Tommi Jaakkola",
        "keywords": ["NLP", "Style Transfer"]
    },
    {
        "name": "Subword regularization: improving neural network translation models with multiple subword candidates",
        "url": "https://arxiv.org/abs/1804.10959",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Taku Kudo",
        "keywords": ["Machine Translation", "NLP", "Regularization"]
    },
    {
        "name": "Supervised learning of probability distributions by neural networks",
        "url": "https://papers.nips.cc/paper/3-supervised-learning-of-probability-distributions-by-neural-networks",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Eric B. Baum, Frank Wilczek",
        "keywords": ["Deep Learning"]
    },
    {
        "name": "Supporting efficient large model training on AMD Instinct^{TM} GPUs with DeepSpeed",
        "url": "https://cloudblogs.microsoft.com/opensource/2022/03/21/supporting-efficient-large-model-training-on-amd-instinct-gpus-with-deepspeed/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Olatunji Ruwase, Jeff Rasley",
        "keywords": ["Deep Learning", "Distributed Training", "Large Models"]
    },
    {
        "name": "Switch transformers: scaling to trillion parameter models with simple and efficient sparsity",
        "url": "https://arxiv.org/abs/2101.03961",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "William Fedus, Barret Zoph, Noam Shazeer",
        "keywords": ["Deep Learning", "Mixture of Experts"]
    },
    {
        "name": "Synchronization in neural nets",
        "url": "https://papers.nips.cc/paper/32-synchronization-in-neural-nets",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Jacques J. Vidal, John Haggerty",
        "keywords": ["Deep Learning"]
    },
    {
        "name": "Tackling the poor assumptions of Naive Bayes text classifiers",
        "url": "https://dl.acm.org/citation.cfm?id=3041916",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Jason D. M. Rennie, Lawrence Shih, Jaime Teevan, David R. Karger",
        "keywords": ["NLP"]
    },
    {
        "name": "Teleporting an unknown quantum state via dual classical and Einstein-Podolsky-Rosen channels",
        "url": "https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.70.1895",
        "topic": "Quantum Computing",
        "datatype": "Paper",
        "authors": "Charles H. Bennett, Gilles Brassard, Claude Cr\u00e9peau, Richard Jozsa, Asher Peres, William K. Wootters",
        "keywords": ["Quantum Computing", "Quantum Teleportation"]
    },
    {
        "name": "The Flan collection: designing data and methods for effective instruction tuning",
        "url": "https://arxiv.org/abs/2301.13688",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny Zhou, Quoc V. Le, Barret Zoph, Jason Wei, Adam Roberts",
        "keywords": ["Instruction Finetuning", "NLP"]
    },
    {
        "name": "The Pile: an 800GB dataset of diverse text for language modeling",
        "url": "https://arxiv.org/abs/2101.00027",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser, Connor Leahy",
        "keywords": ["Dataset", "NLP"]
    },
    {
        "name": "The best of both worlds: combining recent advances in neural machine translation",
        "url": "https://arxiv.org/abs/1804.09849",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Mia Xu Chen, Orhan Firat, Ankur Bapna, Melvin Johnson, Wolfgang Macherey, George Foster, Llion Jones, Mike Schuster, Noam Shazeer, Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, Lukasz Kaiser, Zhifeng Chen, Yonghui Wu, Macduff Hughes",
        "keywords": ["Machine Translation", "NLP"]
    },
    {
        "name": "The elements of statistical learning: data mining, inference and prediction",
        "url": null,
        "topic": "AI, DL, NLP and RL",
        "datatype": "Book",
        "authors": "Trevor Hastie, Robert Tibshirani, Jerome Friedman",
        "keywords": null
    },
    {
        "name": "The information bottleneck method",
        "url": "https://arxiv.org/abs/physics/0004057",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Naftali Tishby, Fernando C. Pereira, William Bialek",
        "keywords": ["Information Theory"]
    },
    {
        "name": "The matrix cookbook",
        "url": null,
        "topic": "Linear Algebra",
        "datatype": "Book",
        "authors": "Kaare Brandt Petersen, Michael Syskind Pedersen",
        "keywords": null
    },
    {
        "name": "The power of scale for parameter-efficient prompt tuning",
        "url": "https://arxiv.org/abs/2104.08691",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Brian Lester, Rami Al-Rfou, Noah Constant",
        "keywords": ["Efficient Finetuning", "NLP"]
    },
    {
        "name": "The wisdom of hindsight makes language models better instruction followers",
        "url": "https://arxiv.org/abs/2302.05206",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Tianjun Zhang, Fangchen Liu, Justin Wong, Pieter Abbeel, Joseph E. Gonzalez",
        "keywords": ["Instruction Finetuning", "NLP"]
    },
    {
        "name": "Thermometer encoding: one hot way to resist adversarial examples",
        "url": "https://openreview.net/forum?id=S18Su--CW",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Jacob Buckman, Aurko Roy, Colin Raffel, Ian Goodfellow",
        "keywords": ["Adversarial Examples", "Deep Learning", "Robustness"]
    },
    {
        "name": "Thomas' calculus",
        "url": null,
        "topic": "Calculus",
        "datatype": "Book",
        "authors": "George B. Thomas Jr., Maurice D. Weir",
        "keywords": null
    },
    {
        "name": "To regularize or not to regularize? The bias variance trade-off in regularized AEs",
        "url": "https://arxiv.org/abs/2006.05838",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Arnab Kumar Mondal, Himanshu Asnani, Parag Singla, Prathosh AP",
        "keywords": ["Deep Learning", "Regularization"]
    },
    {
        "name": "Towards crowdsourced training of large neural networks using decentralized mixture-of-experts",
        "url": "https://arxiv.org/abs/2002.04013",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Max Ryabinin, Anton Gusev",
        "keywords": ["Decentralized Training", "Deep Learning", "Large Models"]
    },
    {
        "name": "Towards deep learning models resilient to adversarial attacks",
        "url": "https://arxiv.org/abs/1706.06083",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, Adrian Vladu",
        "keywords": ["Adversarial Examples", "Deep Learning", "Robustness"]
    },
    {
        "name": "Towards evaluating the robustness of neural networks",
        "url": "https://arxiv.org/abs/1608.04644",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Nicholas Carlini, David Wagner",
        "keywords": ["Adversarial Examples", "Deep Learning", "Robustness"]
    },
    {
        "name": "Train short, test long: Attention with linear biases enables input length extrapolation",
        "url": "https://arxiv.org/abs/2108.12409",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Ofir Press, Noah Smith, Mike Lewis",
        "keywords": ["Embeddings", "NLP", "Transformers"]
    },
    {
        "name": "Training compute-optimal large language models",
        "url": "https://arxiv.org/abs/2203.15556",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican, George van den Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan, Erich Elsen, Jack W. Rae, Oriol Vinyals, Laurent Sifre",
        "keywords": ["Deep Learning", "Large Models", "Transformers"]
    },
    {
        "name": "Training language models to follow instructions with human feedback",
        "url": "https://arxiv.org/abs/2203.02155",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, Ryan Lowe",
        "keywords": ["Instruction Finetuning", "NLP", "Reinforcement Learning"]
    },
    {
        "name": "Transformer memory as a differentiable search index",
        "url": "https://arxiv.org/abs/2202.06991",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Yi Tay, Vinh Q. Tran, Mostafa Dehghani, Jianmo Ni, Dara Bahri, Harsh Mehta, Zhen Qin, Kai Hui, Zhe Zhao, Jai Gupta, Tal Schuster, William W. Cohen, Donald Metzler",
        "keywords": [
            "Information Retrieval",
            "NLP",
            "Retrieval-Augmented Generation"
        ]
    },
    {
        "name": "Transformer quality in linear time",
        "url": "https://arxiv.org/abs/2202.10447",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Weizhe Hua, Zihang Dai, Hanxiao Liu, Quoc Le",
        "keywords": ["Deep Learning", "Transformers"]
    },
    {
        "name": "Transformers explained visually (part 1): overview of functionality",
        "url": "https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Ketan Doshi",
        "keywords": ["Deep Learning", "Transformers"]
    },
    {
        "name": "Transformers explained visually (part 2): how it works, step-by-step",
        "url": "https://towardsdatascience.com/transformers-explained-visually-part-2-how-it-works-step-by-step-b49fa4a64f34",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Ketan Doshi",
        "keywords": ["Deep Learning", "Transformers"]
    },
    {
        "name": "Transformers explained visually (part 3): multi-head attention, deep dive",
        "url": "https://towardsdatascience.com/transformers-explained-visually-part-3-multi-head-attention-deep-dive-1c1ff1024853",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Ketan Doshi",
        "keywords": ["Deep Learning", "Transformers"]
    },
    {
        "name": "Triton: an intermediate language and compiler for tiled neural network computations",
        "url": "https://dl.acm.org/doi/abs/10.1145/3315508.3329973",
        "topic": ["AI, DL, NLP and RL", "Computer Architecture"],
        "datatype": "Paper",
        "authors": "Philippe Tillet, H. T. Kung, David Cox",
        "keywords": ["Computer Architecture", "Deep Learning", "HPC Compiler"]
    },
    {
        "name": "Turing-NLG: a 17-billion-parameter language model by Microsoft",
        "url": "https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Corby Rosset",
        "keywords": ["Deep Learning", "Large Models", "Transformers"]
    },
    {
        "name": "UL2: unifying language learning paradigms",
        "url": "https://arxiv.org/abs/2205.05131",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Jason Wei, Xuezhi Wang, Hyung Won Chung, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng, Denny Zhou, Neil Houlsby, Donald Metzler",
        "keywords": ["Large Models", "NLP", "Transformers"]
    },
    {
        "name": "Understanding convolutional neural networks with a mathematical model",
        "url": "https://arxiv.org/abs/1609.04112",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "C.-C. Jay Kuo",
        "keywords": ["Computer Vision"]
    },
    {
        "name": "Understanding digital signal processing",
        "url": null,
        "topic": "Signal Processing",
        "datatype": "Book",
        "authors": "Richard G. Lyons",
        "keywords": null
    },
    {
        "name": "Understanding disentangling in \u03b2-VAE",
        "url": "https://arxiv.org/abs/1804.03599",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Christopher P. Burgess, Irina Higgins, Arka Pal, Loic Matthey, Nick Watters, Guillaume Desjardins, Alexander Lerchner",
        "keywords": [
            "Deep Learning",
            "Disentanglement",
            "Variational Inference"
        ]
    },
    {
        "name": "Understanding the Open Pre-Trained Transformers (OPT) library",
        "url": "https://towardsdatascience.com/understanding-the-open-pre-trained-transformers-opt-library-193a29c14a15",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Cameron Wolfe",
        "keywords": ["Deep Learning", "Transformers"]
    },
    {
        "name": "Unit tests for stochastic optimization",
        "url": "https://arxiv.org/abs/1312.6055",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Tom Schaul, Ioannis Antonoglou, David Silver",
        "keywords": ["Deep Learning", "Optimization"]
    },
    {
        "name": "Universal language model fine-tuning for text classification",
        "url": "https://arxiv.org/abs/1801.06146",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Jeremy Howard, Sebastian Ruder",
        "keywords": ["NLP", "Text Classification"]
    },
    {
        "name": "Unlimiformer: long-range transformers with unlimited length input",
        "url": "https://arxiv.org/abs/2305.01625",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Amanda Bertsch, Uri Alon, Graham Neubig, Matthew R. Gormley",
        "keywords": ["Long Context Length", "NLP", "Transformers"]
    },
    {
        "name": "Unpaired image-to-image translation using cycle-consistent adversarial networks",
        "url": "https://arxiv.org/abs/1703.10593",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Jun-Yan Zhu, Taesung Park, Phillip Isola, Alexei A. Efros",
        "keywords": [
            "Adversarial Learning",
            "Deep Learning",
            "Generative Models"
        ]
    },
    {
        "name": "Unsupervised machine translation using monolingual corpora only",
        "url": "https://arxiv.org/abs/1711.00043",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Guillaume Lample, Alexis Conneau, Ludovic Denoyer, Marc'Aurelio Ranzato",
        "keywords": ["Machine Translation", "NLP", "Unsupervised Learning"]
    },
    {
        "name": "Unsupervised representation learning by predicting image rotations",
        "url": "https://arxiv.org/abs/1803.07728",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Spyros Gidaris, Praveer Singh, Nikos Komodakis",
        "keywords": ["Computer Vision", "Unsupervised Learning"]
    },
    {
        "name": "Using DeepSpeed and Megatron to train Megatron-Turing NLG 530B, the world\u2019s largest and most powerful generative language model",
        "url": "https://www.microsoft.com/en-us/research/blog/using-deepspeed-and-megatron-to-train-megatron-turing-nlg-530b-the-worlds-largest-and-most-powerful-generative-language-model/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Ali Alvi, Paresh Kharya",
        "keywords": [
            "Distributed Training",
            "Large Models",
            "NLP",
            "Transformers"
        ]
    },
    {
        "name": "VEEGAN: reducing mode collapse in GANs using implicit variational learning",
        "url": "https://arxiv.org/abs/1705.07761",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Akash Srivastava, Lazar Valkov, Chris Russell, Michael U. Gutmann, Charles Sutton",
        "keywords": [
            "Adversarial Learning",
            "Deep Learning",
            "Generative Models"
        ]
    },
    {
        "name": "Variational inference using implicit distributions",
        "url": "https://arxiv.org/abs/1702.08235",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Ferenc Husz\u00e1r",
        "keywords": ["Deep Learning", "Variational Inference"]
    },
    {
        "name": "Variational inference with latent space quantization for adversarial resilience",
        "url": "https://arxiv.org/abs/1903.09940",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Vinay Kyatham, Mayank Mishra, Tarun Kumar Yadav, Deepak Mishra, Prathosh AP",
        "keywords": [
            "Deep Learning",
            "Quantization",
            "Robustness",
            "Variational Inference"
        ]
    },
    {
        "name": "Variational learning for unsupervised knowledge grounded dialogs",
        "url": "https://arxiv.org/abs/2112.00653",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Mayank Mishra, Dhiraj Madan, Gaurav Pandey, Danish Contractor",
        "keywords": ["Dialog", "NLP", "Variational Inference"]
    },
    {
        "name": "Variational lossy autoencoder",
        "url": "https://arxiv.org/abs/1611.02731",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Xi Chen, Diederik P. Kingma, Tim Salimans, Yan Duan, Prafulla Dhariwal, John Schulman, Ilya Sutskever, Pieter Abbeel",
        "keywords": ["Deep Learning", "Variational Inference"]
    },
    {
        "name": "Vector-quantized input-contextualized soft prompts for natural language understanding",
        "url": "https://arxiv.org/abs/2205.11024",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Rishabh Bhardwaj, Amrita Saha, Steven C.H. Hoi, Soujanya Poria",
        "keywords": ["Efficient Finetuning", "NLP"]
    },
    {
        "name": "Very deep convolutional networks for large-scale image recognition",
        "url": "https://arxiv.org/abs/1409.1556",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Karen Simonyan, Andrew Zisserman",
        "keywords": ["Computer Vision", "Image Classification"]
    },
    {
        "name": "Visualizing data using t-SNE",
        "url": "http://www.jmlr.org/papers/v9/vandermaaten08a.html",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Laurens van der Maaten, Geoffrey Hinton",
        "keywords": ["Data Visualization", "Deep Learning"]
    },
    {
        "name": "Wasserstein GAN",
        "url": "https://arxiv.org/abs/1701.07875",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Martin Arjovsky, Soumith Chintala, L\u00e9on Bottou",
        "keywords": [
            "Adversarial Learning",
            "Deep Learning",
            "Generative Models"
        ]
    },
    {
        "name": "Wavenet: a generative model for raw audio",
        "url": "https://arxiv.org/abs/1609.03499",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, Koray Kavukcuoglu",
        "keywords": ["Audio", "Deep Learning", "Generative Models"]
    },
    {
        "name": "WebGPT: browser-assisted question-answering with human feedback",
        "url": "https://arxiv.org/abs/2112.09332",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, John Schulman",
        "keywords": ["Human Feedback", "Reinforcement Learning", "Transformers"]
    },
    {
        "name": "What language model to train if you have one million GPU hours?",
        "url": "https://openreview.net/forum?id=rI7BL3fHIZq",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Teven Le Scao, Thomas Wang, Daniel Hesslow, Lucile Saulnier, Stas Bekman, M Saiful Bari, Stella Biderman, Hady Elsahar, Jason Phang, Ofir Press, Colin Raffel, Victor Sanh, Sheng Shen, Lintang Sutawika, Jaesung Tae, Zheng Xin Yong, Julien Launay, Iz Beltagy",
        "keywords": [
            "Distributed Training",
            "Large Models",
            "NLP",
            "Transformers"
        ]
    },
    {
        "name": "Word translation without parallel data",
        "url": "https://openreview.net/forum?id=H196sainb",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Guillaume Lample, Alexis Conneau, Marc'Aurelio Ranzato, Ludovic Denoyer, Herv\u00e9 J\u00e9gou",
        "keywords": ["Machine Translation", "NLP"]
    },
    {
        "name": "Yandex publishes YaLM 100B. It\u2019s the largest GPT-like neural network in open source",
        "url": "https://medium.com/yandex/yandex-publishes-yalm-100b-its-the-largest-gpt-like-neural-network-in-open-source-d1df53d0e9a6",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "Mikhail Khrushchev",
        "keywords": ["Large Models", "NLP", "Transformers"]
    },
    {
        "name": "You only look once: unified, real-time object detection",
        "url": "https://arxiv.org/abs/1506.02640",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi",
        "keywords": ["Computer Vision", "Object Detection"]
    },
    {
        "name": "ZeRO & DeepSpeed: new system optimizations enable training models with over 100 billion parameters",
        "url": "https://www.microsoft.com/en-us/research/blog/ZeRO-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "DeepSpeed Team, Rangan Majumder, Junhua Wang",
        "keywords": ["Deep Learning", "Distributed Training", "Large Models"]
    },
    {
        "name": "ZeRO++: Extremely efficient collective communication for giant model training",
        "url": "https://arxiv.org/abs/2306.10209",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Guanhua Wang, Heyang Qin, Sam Ade Jacobs, Connor Holmes, Samyam Rajbhandari, Olatunji Ruwase, Feng Yan, Lei Yang, Yuxiong He",
        "keywords": [
            "Deep Learning",
            "Distributed Training",
            "Large Models",
            "Systems"
        ]
    },
    {
        "name": "ZeRO-2 & DeepSpeed: shattering barriers of deep learning speed & scale",
        "url": "https://www.microsoft.com/en-us/research/blog/ZeRO-2-deepspeed-shattering-barriers-of-deep-learning-speed-scale/",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Blog",
        "authors": "DeepSpeed Team, Rangan Majumder, Junhua Wang",
        "keywords": ["Deep Learning", "Distributed Training", "Large Models"]
    },
    {
        "name": "ZeRO-Infinity: breaking the GPU memory wall for extreme scale deep learning",
        "url": "https://arxiv.org/abs/2104.07857",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Samyam Rajbhandari, Olatunji Ruwase, Jeff Rasley, Shaden Smith, Yuxiong He",
        "keywords": [
            "Deep Learning",
            "Distributed Training",
            "Large Models",
            "Transformers"
        ]
    },
    {
        "name": "ZeRO: memory optimizations toward training trillion parameter models",
        "url": "https://arxiv.org/abs/1910.02054",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, Yuxiong He",
        "keywords": [
            "Deep Learning",
            "Distributed Training",
            "Large Models",
            "Transformers"
        ]
    },
    {
        "name": "Zero-shot text-to-image generation",
        "url": "https://arxiv.org/abs/2102.12092",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, Ilya Sutskever",
        "keywords": [
            "Deep Learning",
            "Generative Models",
            "Variational Inference",
            "Zero Shot"
        ]
    },
    {
        "name": "ZeroQuant: efficient and affordable post-training quantization for large-scale transformers",
        "url": "https://arxiv.org/abs/2206.01861",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Zhewei Yao, Reza Yazdani Aminabadi, Minjia Zhang, Xiaoxia Wu, Conglong Li, Yuxiong He",
        "keywords": ["Deep Learning", "Quantization"]
    },
    {
        "name": "mixup: beyond empirical risk minimization",
        "url": "https://arxiv.org/abs/1710.09412v1",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Hongyi Zhang, Moustapha Cisse, Yann N. Dauphin, David Lopez-Paz",
        "keywords": [
            "Adversarial Examples",
            "Adversarial Learning",
            "Deep Learning",
            "Empirical Risk Minimization",
            "Generative Models"
        ]
    },
    {
        "name": "wav2vec 2.0: a framework for self-supervised learning of speech representations",
        "url": "https://arxiv.org/abs/2006.11477",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli",
        "keywords": ["Deep Learning", "Speech", "Transformers"]
    },
    {
        "name": "\u03b2-VAE: learning basic visual concepts with a constrained variational framework",
        "url": "https://openreview.net/forum?id=Sy2fzU9gl",
        "topic": "AI, DL, NLP and RL",
        "datatype": "Paper",
        "authors": "Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, Alexander Lerchner",
        "keywords": ["Deep Learning", "Variational Inference"]
    }
]
